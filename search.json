[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science II with python (Class notes)",
    "section": "",
    "text": "Preface\nThese are class notes for the course STAT303-2. This is not the course text-book. You are required to read the relevant sections of the book as mentioned on the course website.\nThe course notes are currently being written, and will continue to being developed as the course progresses (just like the course textbook last quarter). Please report any typos / mistakes / inconsistencies / issues with the class notes / class presentations in your comments here. Thank you!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Lec1_SimpleLinearRegression.html",
    "href": "Lec1_SimpleLinearRegression.html",
    "title": "1  Simple Linear Regression",
    "section": "",
    "text": "1.1 Simple Linear Regression\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nDevelop a simple linear regression model that predicts car price based on engine size. Datasets to be used: Car_features_train.csv, Car_prices_train.csv\n# We are reading training data ONLY at this point.\n# Test data is already separated in another file\ntrainf = pd.read_csv('./Datasets/Car_features_train.csv') # Predictors\ntrainp = pd.read_csv('./Datasets/Car_prices_train.csv') # Response\ntrain = pd.merge(trainf,trainp)\ntrain.head()\n\n\n\n\n\n\n\n\ncarID\nbrand\nmodel\nyear\ntransmission\nmileage\nfuelType\ntax\nmpg\nengineSize\nprice\n\n\n\n\n0\n18473\nbmw\n6 Series\n2020\nSemi-Auto\n11\nDiesel\n145\n53.3282\n3.0\n37980\n\n\n1\n15064\nbmw\n6 Series\n2019\nSemi-Auto\n10813\nDiesel\n145\n53.0430\n3.0\n33980\n\n\n2\n18268\nbmw\n6 Series\n2020\nSemi-Auto\n6\nDiesel\n145\n53.4379\n3.0\n36850\n\n\n3\n18480\nbmw\n6 Series\n2017\nSemi-Auto\n18895\nDiesel\n145\n51.5140\n3.0\n25998\n\n\n4\n18492\nbmw\n6 Series\n2015\nAutomatic\n62953\nDiesel\n160\n51.4903\n3.0\n18990",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec1_SimpleLinearRegression.html#simple-linear-regression",
    "href": "Lec1_SimpleLinearRegression.html#simple-linear-regression",
    "title": "1  Simple Linear Regression",
    "section": "",
    "text": "1.1.1 Training with statsmodels\nHere, we will use the statsmodels.formula.api module of the statsmodels library. The use of “API” here doesn’t refer to a traditional external web API but rather an interface within the library for users to interact with and perform specific tasks. The statsmodels.formula.api module provides a formulaic interface to the statsmodels library. A formula is a compact way to specify statistical models using a formula language. This module allows users to define statistical models using formulas similar to those used in R.\nSo, in summary, the statsmodels.formula.api module provides a formulaic interface as part of the statsmodels library, allowing users to specify statistical models using a convenient and concise formula syntax.\n\n# Let's create the model\n    \n# ols stands for Ordinary Least Squares - the name of the algorithm that optimizes Linear Regression models\n\n# data input needs the dataframe that has the predictor and the response\n# formula input needs to:\n    # be a string\n    # have the following syntax: \"response~predictor\"\n    \n# Using engineSize to predict price\nols_object = smf.ols(formula = 'price~engineSize', data = train)\n\n\n#Using the fit() function of the 'ols' class to fit the model, i.e., train the model\nmodel = ols_object.fit()\n\n\n#Printing model summary which contains among other things, the model coefficients\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.390\n\n\nModel:\nOLS\nAdj. R-squared:\n0.390\n\n\nMethod:\nLeast Squares\nF-statistic:\n3177.\n\n\nDate:\nTue, 16 Jan 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n16:46:33\nLog-Likelihood:\n-53949.\n\n\nNo. Observations:\n4960\nAIC:\n1.079e+05\n\n\nDf Residuals:\n4958\nBIC:\n1.079e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-4122.0357\n522.260\n-7.893\n0.000\n-5145.896\n-3098.176\n\n\nengineSize\n1.299e+04\n230.450\n56.361\n0.000\n1.25e+04\n1.34e+04\n\n\n\n\n\n\nOmnibus:\n1271.986\nDurbin-Watson:\n0.517\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n6490.719\n\n\nSkew:\n1.137\nProb(JB):\n0.00\n\n\nKurtosis:\n8.122\nCond. No.\n7.64\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe model equation is: \\(\\hat{price}\\) = -4122.0357 + 12990 * engineSize\n\nR-squared is 39%. This is the proportion of variance in car price explained by engineSize.\nThe coef of engineSize (\\(\\hat{\\beta}_1\\)) is statistically significant (\\(p\\)-value = 0). There is a linear relationship between X and Y.\nThe 95% CI of \\(\\hat{\\beta}_1\\) is [1.25e+04, 1.34e+04].\nPI is not shown here.\n\nThe coefficient of engineSize is 1.299e+04. - Unit change in engineSize increases the expected price by \\(\\$\\) 12,990. - An increase of 3 increases the price by \\(\\$\\) (3*1.299e+04) = \\(\\$\\) 38,970.\nThe coefficients can also be returned directly usign the params attribute of the model object returned by the fit() method of the ols class:\n\nmodel.params\n\nIntercept     -4122.035744\nengineSize    12988.281021\ndtype: float64\n\n\nVisualize the regression line\n\nsns.set(font_scale=1.25)\nax = sns.scatterplot(x = train.engineSize, y = train.price,color = 'orange')\nsns.lineplot(x = train.engineSize, y = model.fittedvalues,color = 'blue')\nplt.xlim(-1,7)\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nlegend_elements = [Line2D([0], [0], color='blue', lw=4, label='Predicted (Model)'),\n                   Line2D([0], [0], marker='o', color='w', label='Actual',\n                          markerfacecolor='orange', markersize=10)]\nax.legend(handles=legend_elements, loc='upper left');\n\n\n\n\n\n\n\n\nNote that the above plot can be made directly using the seaborn function regplot(). The function regplot() fits a simple linear regression model with y as the response, and x as the predictor, and then plots the model over a scatteplot of the data.\n\nax = sns.regplot(x = 'engineSize', y = 'price', data = train, color = 'orange',line_kws={\"color\": \"blue\"})\nplt.xlim(-1,7)\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.legend(handles=legend_elements, loc='upper left');\n#Note that some of the engineSize values are 0. They are incorrect, and should ideally be imputed before developing the model.\n\n\n\n\n\n\n\n\nThe light shaded region around the blue line in the above plot is the confidence interval.\nPredict the car price for the cars in the test dataset. Datasets to be used: Car_features_test.csv, Car_prices_test.csv\nNow that the model has been trained, let us evaluate it on unseen data. Make sure that the columns names of the predictors are the same in train and test datasets.\n\n# Read the test data\ntestf = pd.read_csv('./Datasets/Car_features_test.csv') # Predictors\ntestp = pd.read_csv('./Datasets/Car_prices_test.csv') # Response\ntest = pd.merge(testf, testp)\n\n\n#Using the predict() function associated with the 'model' object to make predictions of car price on test (unknown) data\npred_price = model.predict(testf)#Note that the predict() function finds the predictor 'engineSize' in the testf dataframe, and plugs its values in the regression equation for prediction.\n\nMake a visualization that compares the predicted car prices with the actual car prices\n\nsns.scatterplot(x = testp.price, y = pred_price, color = 'orange')\n#In case of a perfect prediction, all the points must lie on the line x = y.\nax = sns.lineplot(x = [0,testp.price.max()], y = [0,testp.price.max()],color='blue') #Plotting the line x = y.\nplt.xlabel('Actual price')\nplt.ylabel('Predicted price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('${x:,.0f}')\nplt.xticks(rotation=20);\n\n\n\n\n\n\n\n\nThe prediction doesn’t look too good. This is because we are just using one predictor - engine size. We can probably improve the model by adding more predictors when we learn multiple linear regression.\nWhat is the RMSE of the predicted car price on unseen data?\n\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n12995.106451548696\n\n\nThe root mean squared error in predicting car price is around $13k.\nWhat is the residual standard error based on the training data?\n\nnp.sqrt(model.mse_resid)\n\n12810.109175214138\n\n\nThe residual standard error on the training data is close to the RMSE on the test data. This shows that the performance of the model on unknown data is comparable to its performance on known data. This implies that the model is not overfitting, which is good! In case we overfit a model on the training data, its performance on unknown data is likely to be worse than that on the training data.\nFind the confidence and prediction intervals of the predicted car price\n\n#Using the get_prediction() function associated with the 'model' object to get the intervals\nintervals = model.get_prediction(testf)\n\n\n#The function requires specifying alpha (probability of Type 1 error) instead of the confidence level to get the intervals\nintervals.summary_frame(alpha=0.05)\n\n\n\n\n\n\n\n\nmean\nmean_se\nmean_ci_lower\nmean_ci_upper\nobs_ci_lower\nobs_ci_upper\n\n\n\n\n0\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n1\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n2\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n3\n8866.245277\n316.580850\n8245.606701\n9486.883853\n-16254.905974\n33987.396528\n\n\n4\n47831.088340\n468.949360\n46911.740050\n48750.436631\n22700.782946\n72961.393735\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2667\n47831.088340\n468.949360\n46911.740050\n48750.436631\n22700.782946\n72961.393735\n\n\n2668\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n2669\n8866.245277\n316.580850\n8245.606701\n9486.883853\n-16254.905974\n33987.396528\n\n\n2670\n21854.526298\n184.135754\n21493.538727\n22215.513869\n-3261.551421\n46970.604017\n\n\n2671\n21854.526298\n184.135754\n21493.538727\n22215.513869\n-3261.551421\n46970.604017\n\n\n\n\n2672 rows × 6 columns\n\n\n\nShow the regression line predicting car price based on engine size for test data. Also show the confidence and prediction intervals for the car price.\n\ninterval_table = intervals.summary_frame(alpha=0.05)\n\n\nax = sns.scatterplot(x = testf.engineSize, y = pred_price,color = 'orange', s = 10)\nsns.lineplot(x = testf.engineSize, y = pred_price, color = 'red')\nsns.lineplot(x = testf.engineSize, y = interval_table.mean_ci_lower, color = 'blue')\nsns.lineplot(x = testf.engineSize, y = interval_table.mean_ci_upper, color = 'blue')\nsns.lineplot(x = testf.engineSize, y = interval_table.obs_ci_lower, color = 'green')\nsns.lineplot(x = testf.engineSize, y = interval_table.obs_ci_upper, color = 'green')\n\nlegend_elements = [Line2D([0], [0], color='red', label='Mean prediction'),\n                   Line2D([0], [0], color='blue', label='Confidence interval'),\n                  Line2D([0], [0], color='green', label='Prediction interval')]\nax.legend(handles=legend_elements, loc='upper left')\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nax.yaxis.set_major_formatter('${x:,.0f}');\n\n\n\n\n\n\n\n\n\n\n1.1.2 Training with sklearn\n\n# Create the model as an object\n\nmodel = LinearRegression() # No inputs, this will change for other models\n\n# Train the model - separate the predictor(s) and the response for this!\nX_train = train[['engineSize']]\ny_train = train[['price']]\n\n# Note that both are dfs, NOT series - necessary to avoid errors\n\nmodel.fit(X_train, y_train)\n\n# Check the slight syntax differences\n    # predictors and response separate\n    # We need to manually slice the predictor column(s) we want to include\n    # No need to assign to an output\n    \n# Return the parameters\nprint(\"Coefficient of engine size = \", model.coef_) # slope\nprint(\"Intercept = \", model.intercept_) # intercept\n\n# No .summary() here! - impossible to do much inference; this is a shortcoming of sklearn\n\nCoefficient of engine size =  [[12988.28102112]]\nIntercept =  [-4122.03574424]\n\n\n\n# Prediction\n\n# Again, separate the predictor(s) and the response of interest\nX_test = test[['engineSize']]\ny_test = test[['price']].to_numpy() # Easier to handle with calculations as np array\n\ny_pred = model.predict(X_test)\n\n# Evaluate\nmodel_rmse = np.sqrt(np.mean((y_pred - y_test)**2)) # RMSE\nmodel_mae = np.mean(np.abs(y_pred - y_test)) # MAE\n\nprint('Test RMSE: ', model_rmse)\n\nTest RMSE:  12995.106451548696\n\n\n\n# Easier way to calculate metrics with sklearn tools\n\n# Note that we have imported the functions 'mean_squared_error' and 'mean_absolute_error'\n# from the sklearn.metrics module (check top of the code)\n\nmodel_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\nmodel_mae = mean_absolute_error(y_test,y_pred)\nprint('Test RMSE: ', model_rmse)\nprint('Test MAE: ', model_mae)\n\nTest RMSE:  12995.106451548696\nTest MAE:  9411.325912951994\n\n\n\ny_pred_train = model.predict(X_train)\nprint('Train R-squared:', r2_score(y_train, y_pred_train))\nprint('Test R-squared:', r2_score(y_test, y_pred))\n\nTrain R-squared: 0.39049842625794573\nTest R-squared: 0.3869900378620146\n\n\nNote: Why did we repeat the same task in two different libraries?\n\nstatsmodels and sklearn have different advantages - we will use both for our purposes\n\nstatsmodels returns a lot of statistical output, which is very helpful for inference (coming up next) but it has a limited variety of models.\nWith statsmodels, you may have columns in your DataFrame in addition to predictors and response, while with sklearn you need to make separate objects consisting of only the predictors and the response.\nsklearn includes many models (Lasso and Ridge this quarter, many others next quarter) and helpful tools/functions (like metrics) that statsmodels does not but it does not have any inference tools.\n\n\n\n\n1.1.3 Training with statsmodels.api\nEarlier we had used the statsmodels.formula.api module, where we had to put the regression model as a formula. We can also use the statsmodels.api module to develop a regression model. The syntax of training a model with the OLS() function in this module is similar to that of sklearn’s LinearRegression() function. However, the order in which the predictors and response are specified is different. The formula-style syntax of the statsmodels.formula.api module is generally preferred. However, depending on the situation, the OLS() syntax of statsmodels.api may be preferred.\nNote that you will manually need to add the predictor (a column of ones) corresponding to the intercept to train the model with this method.\n\n# Create the model as an object\n\n# Train the model - separate the predictor(s) and the response for this!\nX_train = train[['engineSize']]\ny_train = train[['price']]\n\nX_train_with_intercept = np.concatenate((np.ones(X_train.shape[0]).reshape(-1,1), X_train), axis = 1)\n\nmodel = sm.OLS(y_train, X_train_with_intercept).fit()\n    \n# Return the parameters\nprint(model.params) \n\nconst    -4122.035744\nx1       12988.281021\ndtype: float64\n\n\nThe model summary and all other attributes and methods of the model object are the same as that with the object created using the statsmodels.formula.api module.\n\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.390\n\n\nModel:\nOLS\nAdj. R-squared:\n0.390\n\n\nMethod:\nLeast Squares\nF-statistic:\n3177.\n\n\nDate:\nMon, 08 Jan 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n11:17:55\nLog-Likelihood:\n-53949.\n\n\nNo. Observations:\n4960\nAIC:\n1.079e+05\n\n\nDf Residuals:\n4958\nBIC:\n1.079e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nconst\n-4122.0357\n522.260\n-7.893\n0.000\n-5145.896\n-3098.176\n\n\nx1\n1.299e+04\n230.450\n56.361\n0.000\n1.25e+04\n1.34e+04\n\n\n\n\n\n\nOmnibus:\n1271.986\nDurbin-Watson:\n0.517\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n6490.719\n\n\nSkew:\n1.137\nProb(JB):\n0.00\n\n\nKurtosis:\n8.122\nCond. No.\n7.64\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec2_MultipleLinearRegression.html",
    "href": "Lec2_MultipleLinearRegression.html",
    "title": "2  Multiple Linear Regression",
    "section": "",
    "text": "2.1 Multiple Linear Regression\n# importing libraries \nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nDevelop a multiple linear regression model that predicts car price based on engine size, year, mileage, and mpg. Datasets to be used: Car_features_train.csv, Car_prices_train.csv\n# Reading datasets\ntrainf = pd.read_csv('./Datasets/Car_features_train.csv')\ntrainp = pd.read_csv('./Datasets/Car_prices_train.csv')\ntrain = pd.merge(trainf,trainp)\ntrain.head()\n\n\n\n\n\n\n\n\ncarID\nbrand\nmodel\nyear\ntransmission\nmileage\nfuelType\ntax\nmpg\nengineSize\nprice\n\n\n\n\n0\n18473\nbmw\n6 Series\n2020\nSemi-Auto\n11\nDiesel\n145\n53.3282\n3.0\n37980\n\n\n1\n15064\nbmw\n6 Series\n2019\nSemi-Auto\n10813\nDiesel\n145\n53.0430\n3.0\n33980\n\n\n2\n18268\nbmw\n6 Series\n2020\nSemi-Auto\n6\nDiesel\n145\n53.4379\n3.0\n36850\n\n\n3\n18480\nbmw\n6 Series\n2017\nSemi-Auto\n18895\nDiesel\n145\n51.5140\n3.0\n25998\n\n\n4\n18492\nbmw\n6 Series\n2015\nAutomatic\n62953\nDiesel\n160\n51.4903\n3.0\n18990\n#Using the ols function to create an ols object. 'ols' stands for 'Ordinary least squares'\nols_object = smf.ols(formula = 'price~year+mileage+mpg+engineSize', data = train)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.660\n\n\nModel:\nOLS\nAdj. R-squared:\n0.660\n\n\nMethod:\nLeast Squares\nF-statistic:\n2410.\n\n\nDate:\nTue, 27 Dec 2022\nProb (F-statistic):\n0.00\n\n\nTime:\n01:07:25\nLog-Likelihood:\n-52497.\n\n\nNo. Observations:\n4960\nAIC:\n1.050e+05\n\n\nDf Residuals:\n4955\nBIC:\n1.050e+05\n\n\nDf Model:\n4\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-3.661e+06\n1.49e+05\n-24.593\n0.000\n-3.95e+06\n-3.37e+06\n\n\nyear\n1817.7366\n73.751\n24.647\n0.000\n1673.151\n1962.322\n\n\nmileage\n-0.1474\n0.009\n-16.817\n0.000\n-0.165\n-0.130\n\n\nmpg\n-79.3126\n9.338\n-8.493\n0.000\n-97.620\n-61.006\n\n\nengineSize\n1.218e+04\n189.969\n64.107\n0.000\n1.18e+04\n1.26e+04\n\n\n\n\n\n\nOmnibus:\n2450.973\nDurbin-Watson:\n0.541\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n31060.548\n\n\nSkew:\n2.045\nProb(JB):\n0.00\n\n\nKurtosis:\n14.557\nCond. No.\n3.83e+07\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 3.83e+07. This might indicate that there arestrong multicollinearity or other numerical problems.\nThe model equation is: estimated car price = -3.661e6 + 1818 * year -0.15 * mileage - 79.31 * mpg + 12180 * engineSize\nPredict the car price for the cars in the test dataset. Datasets to be used: Car_features_test.csv, Car_prices_test.csv\ntestf = pd.read_csv('./Datasets/Car_features_test.csv')\ntestp = pd.read_csv('./Datasets/Car_prices_test.csv')\n#Using the predict() function associated with the 'model' object to make predictions of car price on test (unknown) data\npred_price = model.predict(testf)#Note that the predict() function finds the predictor 'engineSize' in the testf dataframe, and plugs its values in the regression equation for prediction.\nMake a visualization that compares the predicted car prices with the actual car prices\nsns.scatterplot(x = testp.price, y = pred_price)\n#In case of a perfect prediction, all the points must lie on the line x = y.\nsns.lineplot(x = [0,testp.price.max()], y = [0,testp.price.max()],color='orange') #Plotting the line x = y.\nplt.xlabel('Actual price')\nplt.ylabel('Predicted price')\n\nText(0, 0.5, 'Predicted price')\nThe prediction looks better as compared to the one with simple linear regression. This is because we have four predictors to help explain the variation in car price, instead of just one in the case of simple linear regression. Also, all the predictors have a significant relationship with price as evident from their p-values. Thus, all four of them are contributing in explaining the variation. Note the higher values of R2 as compared to the one in the case of simple linear regression.\nWhat is the RMSE of the predicted car price?\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n9956.82497993548\nWhat is the residual standard error based on the training data?\nnp.sqrt(model.mse_resid)\n\n9563.74782917604\nsns.scatterplot(x = model.fittedvalues, y=model.resid,color = 'orange')\nsns.lineplot(x = [pred_price.min(),pred_price.max()],y = [0,0],color = 'blue')\nplt.xlabel('Predicted price')\nplt.ylabel('Residual')\n\nText(0, 0.5, 'Residual')\nWill the explained variation (R-squared) in car price always increase if we add a variable?\nShould we keep on adding variables as long as the explained variation (R-squared) is increasing?\n#Using the ols function to create an ols object. 'ols' stands for 'Ordinary least squares'\nnp.random.seed(1)\ntrain['rand_col'] = np.random.rand(train.shape[0])\nols_object = smf.ols(formula = 'price~year+mileage+mpg+engineSize+rand_col', data = train)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.661\n\n\nModel:\nOLS\nAdj. R-squared:\n0.660\n\n\nMethod:\nLeast Squares\nF-statistic:\n1928.\n\n\nDate:\nTue, 27 Dec 2022\nProb (F-statistic):\n0.00\n\n\nTime:\n01:07:38\nLog-Likelihood:\n-52497.\n\n\nNo. Observations:\n4960\nAIC:\n1.050e+05\n\n\nDf Residuals:\n4954\nBIC:\n1.050e+05\n\n\nDf Model:\n5\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-3.662e+06\n1.49e+05\n-24.600\n0.000\n-3.95e+06\n-3.37e+06\n\n\nyear\n1818.1672\n73.753\n24.652\n0.000\n1673.578\n1962.756\n\n\nmileage\n-0.1474\n0.009\n-16.809\n0.000\n-0.165\n-0.130\n\n\nmpg\n-79.2837\n9.338\n-8.490\n0.000\n-97.591\n-60.976\n\n\nengineSize\n1.218e+04\n189.972\n64.109\n0.000\n1.18e+04\n1.26e+04\n\n\nrand_col\n451.1226\n471.897\n0.956\n0.339\n-474.004\n1376.249\n\n\n\n\n\n\nOmnibus:\n2451.728\nDurbin-Watson:\n0.541\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n31040.331\n\n\nSkew:\n2.046\nProb(JB):\n0.00\n\n\nKurtosis:\n14.552\nCond. No.\n3.83e+07\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 3.83e+07. This might indicate that there arestrong multicollinearity or other numerical problems.\nAdding a variable with random values to the model (rand_col) increased the explained variation (R-squared). This is because the model has one more parameter to tune to reduce the residual squared error (RSS). However, the p-value of rand_col suggests that its coefficient is zero. Thus, using the model with rand_col may give poorer performance on unknown data, as compared to the model without rand_col. This implies that it is not a good idea to blindly add variables in the model to increase R-squared.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html",
    "href": "Assignment 1 (Section 20).html",
    "title": "Assignment 1 (Section 20)",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#instructions",
    "href": "Assignment 1 (Section 20).html#instructions",
    "title": "Assignment 1 (Section 20)",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nDo not write your name on the assignment.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Wednesday, 24th January 2024 at 11:59 pm.\nThere is a bonus question worth 15 points.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 100 + 15 (bonus question) + 5 (proper formatting) = 120 out of 100. There is no partial credit for some parts of the bonus question.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "href": "Assignment 1 (Section 20).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "title": "Assignment 1 (Section 20)",
    "section": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)",
    "text": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)\n\n1a)\nFor each case below, explain (1) whether it is a classification or a regression problem and (2) whether the main purpose is prediction or inference. You need justify your answers for credit.\n\n\n1b)\nYou work for a company that is interested in conducting a marketing campaign. The goal of your project is to identify individuals who are likely to respond positively to a marketing campaign, based on observations of demographic variables (such as age, gender, income etc.) measured on each individual. (2+2 points)\n\n\n1c)\nFor the same company, now you are working on a different project. This one is focused on understanding the impact of advertisements in different media types on the company sales. For example, you are interested in the following question: ‘How large of an increase in sales is associated with a given increase in radio and TV advertising?’ (2+2 points)\n\n\n1d)\nA company is selling furniture and they are interested in the finding the association between demographic characteristics of customers (such as age, gender, income etc.) and if they would purchase a particular company product. (2+2 points)\n\n\n1e)\nWe are interested in forecasting the % change in the USD/Euro exchange rate using the weekly changes in the stock markets of a number of countries. We collect weekly data for all of 2023. For each week, we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market. (2+2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "href": "Assignment 1 (Section 20).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "title": "Assignment 1 (Section 20)",
    "section": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)",
    "text": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)\n\n2a)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the root mean squared error (RMSE) metric as compared to the mean absolute error (MAE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.\n\n\n2b)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the mean absolute error (MAE) metric as compared to the root mean squared error (RMSE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#modeling-the-petrol-consumption-in-u.s.-states-61-points",
    "href": "Assignment 1 (Section 20).html#modeling-the-petrol-consumption-in-u.s.-states-61-points",
    "title": "Assignment 1 (Section 20)",
    "section": "3) Modeling the Petrol Consumption in U.S. States (61 points)",
    "text": "3) Modeling the Petrol Consumption in U.S. States (61 points)\nRead petrol_consumption_train.csv. Assume that each observation is a U.S. state. For each observation, the data has the following variables as its five columns:\nPetrol_tax: Petrol tax (cents per gallon)\nPer_capita_income: Average income (dollars)\nPaved_highways: Paved Highways (miles)\nProp_license: Proportion of population with driver’s licenses\nPetrol_consumption: Consumption of petrol (millions of gallons)\n\n3a)\nCreate a pairwise plot of all the variables in the dataset. (1 point) Print the correlation matrix of all the variables as well. (1 point) Which variable has the highest linear correlation with Petrol_consumption? (2 points)\nNote: Remember that a pairwise plot is a visualization tool that you can find in the seaborn library.\n\n\n3b)\nFit a simple linear regression model to predict Petrol_consumption using the column you found in part a as the only predictor. Print the model summary. (4 points)\n\n\n3c)\nWhat is the increase in petrol consumption for an increase of 0.05 in the predictor? (4 points)\n\n\n3d)\nDoes petrol consumption have a statistically significant relationship with the predictor? You need to justify your answer for credit. (4 points)\n\n\n3e)\nHow much of the variation in petrol consumption can be explained by its linear relationship with the predictor? (3 points)\n\n\n3f)\nPredict the petrol consumption for a state in which 50% of the population has a driver’s license. (3 points) What are the confidence interval (3 points) and the prediction interval (3 points) for your prediction? Which interval is wider? (1 points) Why? (2 points)\n\n\n3g)\nPredict the petrol consumption for a state in which 10% of the population has a driver’s license. (3 points) Are you getting a reasonable outcome? (1 point) Why or why not? (2 points)\n\n\n3h)\nWhat is the residual standard error of the model? (3 points)\n\n\n3i)\nUsing the trained model, predict the petrol consumption of the observations in petrol_consumption_test.csv (2 points) and find the RMSE. (2 points) What is the unit of this RMSE value? (1 point)\n\n\n3j)\nBased on the answers to part g and part h, do you think the model is overfitting? You need to justify your answer for credit. (4 points)\n\n\n3k)\nMake a scatterplot of Petrol_consumption vs. the predictor using petrol_consumption_test.csv. (1 point) Over the scatterplot, plot the regression line (2 points), the prediction interval (2 points), and the confidence interval. (2 points)\nMake sure that regression line, prediction interval lines, and confidence interval lines have different colors. (1 point) Display a legend that correctly labels the lines as well. (1 point) Note that you need two lines of the same color to plot an interval.\n\n\n3l)\nFind the correlation between Petrol_consumption and the rest of the variables in petrol_consumption_train.csv. Which column would have the lowest R-squared value when used as the predictor for a Simple Linear Regression model to predict Petrol_consumption? Note that you can directly answer this question from the correlation values and do not need to develop any more linear regression models. (3 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#reproducing-the-results-with-scikit-learn-15-points",
    "href": "Assignment 1 (Section 20).html#reproducing-the-results-with-scikit-learn-15-points",
    "title": "Assignment 1 (Section 20)",
    "section": "4) Reproducing the Results with Scikit-Learn (15 points)",
    "text": "4) Reproducing the Results with Scikit-Learn (15 points)\n\n4a)\nUsing the same datasets, same response and the same predictor as Question 3, reproduce the following outputs with scikit-learn:\n\nModel RMSE for test data (3 points)\nR-squared value of the model (3 points)\nResidual standard error of the model (3 points)\n\nNote that you are only allowed to use scikit-learn, pandas, and numpy tools for this question. Any other libraries will not receive any credit.\n\n\n4b)\nWhich of the model outputs from Question 3 cannot be reproduced using scikit-learn? Give two answers. (2+2 points) What does this tell about scikit-learn? (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#bonus-question-15-points",
    "href": "Assignment 1 (Section 20).html#bonus-question-15-points",
    "title": "Assignment 1 (Section 20)",
    "section": "5) Bonus Question (15 points)",
    "text": "5) Bonus Question (15 points)\nPlease note that the bonus question requires you to look more into the usage of the tools we covered in class and it will be necessary to do your own research. We strongly suggest attempting it after you are done with the rest of the assignment.\n\n5a)\nFit a simple linear regression model to predict Petrol_consumption based on the predictor in Question 3, but without an intercept term. (5 points - no partial credit)\nWithout an intercept means that the equation becomes \\(Y = \\beta_1X\\). The intercept term, \\(\\beta_0\\), becomes 0.\nNote: You must answer this part correctly to qualify for the bonus points in the following parts.\n\n\n5b)\nPredict the petrol consumption for the observations in petrol_consumption_test.csv using the model without an intercept and find the RMSE. (1+2 points) Then, print the summary and find the R-squared. (2 points)\n\n\n5c)\nThe RMSE for the models with and without the intercept are similar, which indicates that both models are almost equally good. However, the R-squared for the model without intercept is much higher than the R-squared for the model with the intercept. Why? Justify your answer. (5 points - no partial credit)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html",
    "href": "Assignment 1 (Sections 21 & 22).html",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#instructions",
    "href": "Assignment 1 (Sections 21 & 22).html#instructions",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nDo not write your name on the assignment.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Wednesday, 24th January 2024 at 11:59 pm.\nThere is a bonus question worth 15 points.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 100 + 15 (bonus question) + 5 (proper formatting) = 120 out of 100. There is no partial credit for some parts of the bonus question.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "href": "Assignment 1 (Sections 21 & 22).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)",
    "text": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)\nFor each case below, explain (1) whether it is a classification or a regression problem and (2) whether the main purpose is prediction or inference. You need justify your answers for credit.\n\n1a)\nYou work for a company that is interested in conducting a marketing campaign. The goal of your project is to identify individuals who are likely to respond positively to a marketing campaign, based on observations of demographic variables (such as age, gender, income etc.) measured on each individual. (2+2 points)\n\n\n1b)\nFor the same company, now you are working on a different project. This one is focused on understanding the impact of advertisements in different media types on the company sales. For example, you are interested in the following question: ‘How large of an increase in sales is associated with a given increase in radio and TV advertising?’ (2+2 points)\n\n\n1c)\nA company is selling furniture and they are interested in the finding the association between demographic characteristics of customers (such as age, gender, income etc.) and if they would purchase a particular company product. (2+2 points)\n\n\n1d)\nWe are interested in forecasting the % change in the USD/Euro exchange rate using the weekly changes in the stock markets of a number of countries. We collect weekly data for all of 2023. For each week, we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market. (2+2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "href": "Assignment 1 (Sections 21 & 22).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)",
    "text": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)\n\n2a)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the root mean squared error (RMSE) metric as compared to the mean absolute error (MAE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.\n\n\n2b)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the mean absolute error (MAE) metric as compared to the root mean squared error (RMSE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#simple-linear-regression-formulation-3-points",
    "href": "Assignment 1 (Sections 21 & 22).html#simple-linear-regression-formulation-3-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "3) Simple Linear Regression: Formulation (3 points)",
    "text": "3) Simple Linear Regression: Formulation (3 points)\nWhen asked to state the simple linear regression model, a students wrote it as follows: \\(E(Y_i) = \\beta_0 + \\beta_1X_i + \\epsilon_i\\). Is this correct (1 point)? Justify your answer (2 points).",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#modeling-the-petrol-consumption-in-u.s.-states-58-points",
    "href": "Assignment 1 (Sections 21 & 22).html#modeling-the-petrol-consumption-in-u.s.-states-58-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "4) Modeling the Petrol Consumption in U.S. States (58 points)",
    "text": "4) Modeling the Petrol Consumption in U.S. States (58 points)\nRead petrol_consumption_train.csv. Assume that each observation is a U.S. state. For each observation, the data has the following variables as its five columns:\nPetrol_tax: Petrol tax (cents per gallon)\nPer_capita_income: Average income (dollars)\nPaved_highways: Paved Highways (miles)\nProp_license: Proportion of population with driver’s licenses\nPetrol_consumption: Consumption of petrol (millions of gallons)\n\n4a)\nCreate a pairwise plot of all the variables in the dataset. (1 point) Print the correlation matrix of all the variables as well. (1 point) Which variable has the highest linear correlation with Petrol_consumption? (1 point)\nNote: Remember that a pairwise plot is a visualization tool that you can find in the seaborn library.\n\n\n4b)\nFit a simple linear regression model to predict Petrol_consumption using the column you found in part a as the only predictor. Print the model summary. (3 points)\n\n\n4c)\nWhen asked for a point estimate of the expected petrol consumption for a state where the proportion of population with driver’s license is 54.4%, a person gave the estimate 488 million gallons because that is the mean value of Petrol_consumption for the two observations of Prop_license = 0.544 pieces in the dataset. Is there an issue with this approach? Explain. (2 points) If there is an issue, then suggest a better approach and use it to estimate the expected petrol consumption for a state where the proportion of population with driver’s license is 54.4%. (2 points)\n\n\n4d)\nWhat is the increase in petrol consumption for an increase of 0.05 in the predictor? (3 points)\n\n\n4e)\nDoes petrol consumption have a statistically significant relationship with the predictor? You need to justify your answer for credit. (3 points)\n\n\n4f)\nHow much of the variation in petrol consumption can be explained by its linear relationship with the predictor? (2 points)\n\n\n4g)\nPredict the petrol consumption for a state in which 50% of the population has a driver’s license. (2 points) What are the confidence interval (2 points) and the prediction interval (2 points) for your prediction? Which interval is wider? (1 points) Why? (2 points)\n\n\n4h)\nPredict the petrol consumption for a state in which 10% of the population has a driver’s license. (3 points) Are you getting a reasonable outcome? (1 point) Why or why not? (2 points)\n\n\n4i)\nWhat is the residual standard error of the model? (3 points)\n\n\n4j)\nUsing the trained model, predict the petrol consumption of the observations in petrol_consumption_test.csv (2 points) and find the RMSE. (2 points) What is the unit of this RMSE value? (1 point)\n\n\n4k)\nBased on the answers to part i and part j, do you think the model is overfitting? You need to justify your answer for credit. (3 points)\n\n\n4l)\nMake a scatterplot of Petrol_consumption vs. the predictor using petrol_consumption_test.csv. (1 point) Over the scatterplot, plot the regression line (1 point), the prediction interval (2 points), and the confidence interval. (2 points)\nMake sure that regression line, prediction interval lines, and confidence interval lines have different colors. (1 point) Display a legend that correctly labels the lines as well. (1 point) Note that you need two lines of the same color to plot an interval.\n\n\n4m)\nThe dataset consists of 40 US States. If you combine this data with the data of the remaining 10 US States, are you likely to obtain narrower confidence and prediction intervals in the plot developed in the previous question, for the same level of confidence? Justify your answer. (2 points).\nIf yes, then can you gaurantee that the width of these intervals will reduce? Justify your answer. If no, then can you gaurantee that the width of these intervals will not reduce? Justify your answer. (2 points)\n\n\n4n)\nFind the correlation between Petrol_consumption and the rest of the variables in petrol_consumption_train.csv. Which column would have the lowest R-squared value when used as the predictor for a Simple Linear Regression model to predict Petrol_consumption? Note that you can directly answer this question from the correlation values and do not need to develop any more linear regression models. (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#reproducing-the-results-with-scikit-learn-15-points",
    "href": "Assignment 1 (Sections 21 & 22).html#reproducing-the-results-with-scikit-learn-15-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "5) Reproducing the Results with Scikit-Learn (15 points)",
    "text": "5) Reproducing the Results with Scikit-Learn (15 points)\n\n5a)\nUsing the same datasets, same response and the same predictor as Question 4, reproduce the following outputs with scikit-learn:\n\nModel RMSE for test data (3 points)\nR-squared value of the model (3 points)\nResidual standard error of the model (3 points)\n\nNote that you are only allowed to use scikit-learn, pandas, and numpy tools for this question. Any other libraries will not receive any credit.\n\n\n5b)\nWhich of the model outputs from Question 4 cannot be reproduced using scikit-learn? Give two answers. (2+2 points) What does this tell about scikit-learn? (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#bonus-question-15-points",
    "href": "Assignment 1 (Sections 21 & 22).html#bonus-question-15-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "6) Bonus Question (15 points)",
    "text": "6) Bonus Question (15 points)\nPlease note that the bonus question requires you to look more into the usage of the tools we covered in class and it will be necessary to do your own research. We strongly suggest attempting it after you are done with the rest of the assignment.\n\n6a)\nFit a simple linear regression model to predict Petrol_consumption based on the predictor in Question 4, but without an intercept term. (5 points - no partial credit)\nWithout an intercept means that the equation becomes \\(Y = \\beta_1X\\). The intercept term, \\(\\beta_0\\), becomes 0.\nNote: You must answer this part correctly to qualify for the bonus points in the following parts.\n\n\n6b)\nPredict the petrol consumption for the observations in petrol_consumption_test.csv using the model without an intercept and find the RMSE. (1+2 points) Then, print the summary and find the R-squared. (2 points)\n\n\n6c)\nThe RMSE for the models with and without the intercept are similar, which indicates that both models are almost equally good. However, the R-squared for the model without intercept is much higher than the R-squared for the model with the intercept. Why? Justify your answer. (5 points - no partial credit)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html",
    "href": "Assignment 2.html",
    "title": "5  Assignment 2",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#instructions",
    "href": "Assignment 2.html#instructions",
    "title": "5  Assignment 2",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Sunday, 4th February 2024 at 11:59 pm.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 105 + 5 (proper formatting) = 110 out of 100.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#multiple-linear-regression-24-points",
    "href": "Assignment 2.html#multiple-linear-regression-24-points",
    "title": "5  Assignment 2",
    "section": "5.1 1) Multiple Linear Regression (24 points)",
    "text": "5.1 1) Multiple Linear Regression (24 points)\nA study was conducted on 97 male patients with prostate cancer who were due to receive a radical prostatectomy (complete removal of the prostate). The prostate.csv file contains data on 9 measurements taken from these 97 patients. Each row (observation) represents a patient and each column (variable) represents a measurement. The description of variables can be found here: https://rafalab.github.io/pages/649/prostate.html\n\n5.1.1 1a)\nFit a linear regression model with lpsa as the response and all the other variables as the predictors. Print its summary. (2 points) Write down the optimal equation that predicts lpsa using the predictors. (2 points)\n\n\n5.1.2 1b)\nIs the overall regression statistically significant? In other words, is there a statistically significant relationship between the response and at least one predictor? You need to justify your answer for credit. (2 points)\n\n\n5.1.3 1c)\nWhat does the optimal coefficient of svi tell us as a numeric output? Make sure you include the predictor, (svi) the response (lpsa) and the other predictors in your answer. (2 points)\n\n\n5.1.4 1d)\nCheck the \\(p\\)-values of gleason and age. Are these predictors statistically significant? You need to justify your answer for credit. (2 points)\n\n\n5.1.5 1e)\nCheck the 95% Confidence Interval of age. How can you relate it to its p-value and statistical significance, which you found in the previous part? (2 points)\n\n\n5.1.6 1f)\nThis question requires some thinking, and bringing your 303-1 and 303-2 knowledge together.\nFit a simple linear regression model on lpsa against gleason and check the \\(p\\)-value of gleason using the summary. (2 point) Did the statistical significance of gleason change in the absence of other predictors? (1 point) Why or why not? (3 points)\nHints:\n\nYou need to compare this model with the Multiple Linear Regression model you created above.\nPrinting a correlation matrix of all the predictors should be useful.\n\n\n\n5.1.7 1g)\nPredict the lpsa of a 65 year old man with lcavol = 1.35, lweight = 3.65, lbph = 0.1, svi = 0.22, lcp = -0.18, gleason = 6.75, and pgg45 = 25. Find the 95% confidence and prediction intervals as well. (2 points)\n\n\n5.1.8 1h)\nIn the Multiple Linear Regression model with all the predictors, you should see a total of five predictors that appear to be statistically insignificant. Why is it not a good idea to directly conclude that all of them are statistically insignificant? (2 points) Implement the additional test that concludes the statistical insignificance of all five predictors. (2 points)\nHint: f_test() method",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  }
]