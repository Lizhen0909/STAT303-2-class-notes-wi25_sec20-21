[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science II with python (Class notes)",
    "section": "",
    "text": "Preface\nThese are class notes for the course STAT303-2. This is not the course text-book. You are required to read the relevant sections of the book as mentioned on the course website.\nThe course notes are currently being written, and will continue to being developed as the course progresses (just like the course textbook last quarter). Please report any typos / mistakes / inconsistencies / issues with the class notes / class presentations in your comments here. Thank you!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Lec1_SimpleLinearRegression.html",
    "href": "Lec1_SimpleLinearRegression.html",
    "title": "1  Simple Linear Regression",
    "section": "",
    "text": "1.1 Simple Linear Regression\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nDevelop a simple linear regression model that predicts car price based on engine size. Datasets to be used: Car_features_train.csv, Car_prices_train.csv\n# We are reading training data ONLY at this point.\n# Test data is already separated in another file\ntrainf = pd.read_csv('./Datasets/Car_features_train.csv') # Predictors\ntrainp = pd.read_csv('./Datasets/Car_prices_train.csv') # Response\ntrain = pd.merge(trainf,trainp)\ntrain.head()\n\n\n\n\n\n\n\n\ncarID\nbrand\nmodel\nyear\ntransmission\nmileage\nfuelType\ntax\nmpg\nengineSize\nprice\n\n\n\n\n0\n18473\nbmw\n6 Series\n2020\nSemi-Auto\n11\nDiesel\n145\n53.3282\n3.0\n37980\n\n\n1\n15064\nbmw\n6 Series\n2019\nSemi-Auto\n10813\nDiesel\n145\n53.0430\n3.0\n33980\n\n\n2\n18268\nbmw\n6 Series\n2020\nSemi-Auto\n6\nDiesel\n145\n53.4379\n3.0\n36850\n\n\n3\n18480\nbmw\n6 Series\n2017\nSemi-Auto\n18895\nDiesel\n145\n51.5140\n3.0\n25998\n\n\n4\n18492\nbmw\n6 Series\n2015\nAutomatic\n62953\nDiesel\n160\n51.4903\n3.0\n18990",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec1_SimpleLinearRegression.html#simple-linear-regression",
    "href": "Lec1_SimpleLinearRegression.html#simple-linear-regression",
    "title": "1  Simple Linear Regression",
    "section": "",
    "text": "1.1.1 Training with statsmodels\nHere, we will use the statsmodels.formula.api module of the statsmodels library. The use of “API” here doesn’t refer to a traditional external web API but rather an interface within the library for users to interact with and perform specific tasks. The statsmodels.formula.api module provides a formulaic interface to the statsmodels library. A formula is a compact way to specify statistical models using a formula language. This module allows users to define statistical models using formulas similar to those used in R.\nSo, in summary, the statsmodels.formula.api module provides a formulaic interface as part of the statsmodels library, allowing users to specify statistical models using a convenient and concise formula syntax.\n\n# Let's create the model\n    \n# ols stands for Ordinary Least Squares - the name of the algorithm that optimizes Linear Regression models\n\n# data input needs the dataframe that has the predictor and the response\n# formula input needs to:\n    # be a string\n    # have the following syntax: \"response~predictor\"\n    \n# Using engineSize to predict price\nols_object = smf.ols(formula = 'price~engineSize', data = train)\n\n\n#Using the fit() function of the 'ols' class to fit the model, i.e., train the model\nmodel = ols_object.fit()\n\n\n#Printing model summary which contains among other things, the model coefficients\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.390\n\n\nModel:\nOLS\nAdj. R-squared:\n0.390\n\n\nMethod:\nLeast Squares\nF-statistic:\n3177.\n\n\nDate:\nTue, 16 Jan 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n16:46:33\nLog-Likelihood:\n-53949.\n\n\nNo. Observations:\n4960\nAIC:\n1.079e+05\n\n\nDf Residuals:\n4958\nBIC:\n1.079e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-4122.0357\n522.260\n-7.893\n0.000\n-5145.896\n-3098.176\n\n\nengineSize\n1.299e+04\n230.450\n56.361\n0.000\n1.25e+04\n1.34e+04\n\n\n\n\n\n\nOmnibus:\n1271.986\nDurbin-Watson:\n0.517\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n6490.719\n\n\nSkew:\n1.137\nProb(JB):\n0.00\n\n\nKurtosis:\n8.122\nCond. No.\n7.64\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe model equation is: \\(\\hat{price}\\) = -4122.0357 + 12990 * engineSize\n\nR-squared is 39%. This is the proportion of variance in car price explained by engineSize.\nThe coef of engineSize (\\(\\hat{\\beta}_1\\)) is statistically significant (\\(p\\)-value = 0). There is a linear relationship between X and Y.\nThe 95% CI of \\(\\hat{\\beta}_1\\) is [1.25e+04, 1.34e+04].\nPI is not shown here.\n\nThe coefficient of engineSize is 1.299e+04. - Unit change in engineSize increases the expected price by \\(\\$\\) 12,990. - An increase of 3 increases the price by \\(\\$\\) (3*1.299e+04) = \\(\\$\\) 38,970.\nThe coefficients can also be returned directly usign the params attribute of the model object returned by the fit() method of the ols class:\n\nmodel.params\n\nIntercept     -4122.035744\nengineSize    12988.281021\ndtype: float64\n\n\nVisualize the regression line\n\nsns.set(font_scale=1.25)\nax = sns.scatterplot(x = train.engineSize, y = train.price,color = 'orange')\nsns.lineplot(x = train.engineSize, y = model.fittedvalues,color = 'blue')\nplt.xlim(-1,7)\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nlegend_elements = [Line2D([0], [0], color='blue', lw=4, label='Predicted (Model)'),\n                   Line2D([0], [0], marker='o', color='w', label='Actual',\n                          markerfacecolor='orange', markersize=10)]\nax.legend(handles=legend_elements, loc='upper left');\n\n\n\n\n\n\n\n\nNote that the above plot can be made directly using the seaborn function regplot(). The function regplot() fits a simple linear regression model with y as the response, and x as the predictor, and then plots the model over a scatteplot of the data.\n\nax = sns.regplot(x = 'engineSize', y = 'price', data = train, color = 'orange',line_kws={\"color\": \"blue\"})\nplt.xlim(-1,7)\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.legend(handles=legend_elements, loc='upper left');\n#Note that some of the engineSize values are 0. They are incorrect, and should ideally be imputed before developing the model.\n\n\n\n\n\n\n\n\nThe light shaded region around the blue line in the above plot is the confidence interval.\nPredict the car price for the cars in the test dataset. Datasets to be used: Car_features_test.csv, Car_prices_test.csv\nNow that the model has been trained, let us evaluate it on unseen data. Make sure that the columns names of the predictors are the same in train and test datasets.\n\n# Read the test data\ntestf = pd.read_csv('./Datasets/Car_features_test.csv') # Predictors\ntestp = pd.read_csv('./Datasets/Car_prices_test.csv') # Response\ntest = pd.merge(testf, testp)\n\n\n#Using the predict() function associated with the 'model' object to make predictions of car price on test (unknown) data\npred_price = model.predict(testf)#Note that the predict() function finds the predictor 'engineSize' in the testf dataframe, and plugs its values in the regression equation for prediction.\n\nMake a visualization that compares the predicted car prices with the actual car prices\n\nsns.scatterplot(x = testp.price, y = pred_price, color = 'orange')\n#In case of a perfect prediction, all the points must lie on the line x = y.\nax = sns.lineplot(x = [0,testp.price.max()], y = [0,testp.price.max()],color='blue') #Plotting the line x = y.\nplt.xlabel('Actual price')\nplt.ylabel('Predicted price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('${x:,.0f}')\nplt.xticks(rotation=20);\n\n\n\n\n\n\n\n\nThe prediction doesn’t look too good. This is because we are just using one predictor - engine size. We can probably improve the model by adding more predictors when we learn multiple linear regression.\nWhat is the RMSE of the predicted car price on unseen data?\n\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n12995.106451548696\n\n\nThe root mean squared error in predicting car price is around $13k.\nWhat is the residual standard error based on the training data?\n\nnp.sqrt(model.mse_resid)\n\n12810.109175214138\n\n\nThe residual standard error on the training data is close to the RMSE on the test data. This shows that the performance of the model on unknown data is comparable to its performance on known data. This implies that the model is not overfitting, which is good! In case we overfit a model on the training data, its performance on unknown data is likely to be worse than that on the training data.\nFind the confidence and prediction intervals of the predicted car price\n\n#Using the get_prediction() function associated with the 'model' object to get the intervals\nintervals = model.get_prediction(testf)\n\n\n#The function requires specifying alpha (probability of Type 1 error) instead of the confidence level to get the intervals\nintervals.summary_frame(alpha=0.05)\n\n\n\n\n\n\n\n\nmean\nmean_se\nmean_ci_lower\nmean_ci_upper\nobs_ci_lower\nobs_ci_upper\n\n\n\n\n0\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n1\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n2\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n3\n8866.245277\n316.580850\n8245.606701\n9486.883853\n-16254.905974\n33987.396528\n\n\n4\n47831.088340\n468.949360\n46911.740050\n48750.436631\n22700.782946\n72961.393735\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2667\n47831.088340\n468.949360\n46911.740050\n48750.436631\n22700.782946\n72961.393735\n\n\n2668\n34842.807319\n271.666459\n34310.220826\n35375.393812\n9723.677232\n59961.937406\n\n\n2669\n8866.245277\n316.580850\n8245.606701\n9486.883853\n-16254.905974\n33987.396528\n\n\n2670\n21854.526298\n184.135754\n21493.538727\n22215.513869\n-3261.551421\n46970.604017\n\n\n2671\n21854.526298\n184.135754\n21493.538727\n22215.513869\n-3261.551421\n46970.604017\n\n\n\n\n2672 rows × 6 columns\n\n\n\nShow the regression line predicting car price based on engine size for test data. Also show the confidence and prediction intervals for the car price.\n\ninterval_table = intervals.summary_frame(alpha=0.05)\n\n\nax = sns.scatterplot(x = testf.engineSize, y = pred_price,color = 'orange', s = 10)\nsns.lineplot(x = testf.engineSize, y = pred_price, color = 'red')\nsns.lineplot(x = testf.engineSize, y = interval_table.mean_ci_lower, color = 'blue')\nsns.lineplot(x = testf.engineSize, y = interval_table.mean_ci_upper, color = 'blue')\nsns.lineplot(x = testf.engineSize, y = interval_table.obs_ci_lower, color = 'green')\nsns.lineplot(x = testf.engineSize, y = interval_table.obs_ci_upper, color = 'green')\n\nlegend_elements = [Line2D([0], [0], color='red', label='Mean prediction'),\n                   Line2D([0], [0], color='blue', label='Confidence interval'),\n                  Line2D([0], [0], color='green', label='Prediction interval')]\nax.legend(handles=legend_elements, loc='upper left')\nplt.xlabel('Engine size (in litres)')\nplt.ylabel('Car price')\nax.yaxis.set_major_formatter('${x:,.0f}');\n\n\n\n\n\n\n\n\n\n\n1.1.2 Training with sklearn\n\n# Create the model as an object\n\nmodel = LinearRegression() # No inputs, this will change for other models\n\n# Train the model - separate the predictor(s) and the response for this!\nX_train = train[['engineSize']]\ny_train = train[['price']]\n\n# Note that both are dfs, NOT series - necessary to avoid errors\n\nmodel.fit(X_train, y_train)\n\n# Check the slight syntax differences\n    # predictors and response separate\n    # We need to manually slice the predictor column(s) we want to include\n    # No need to assign to an output\n    \n# Return the parameters\nprint(\"Coefficient of engine size = \", model.coef_) # slope\nprint(\"Intercept = \", model.intercept_) # intercept\n\n# No .summary() here! - impossible to do much inference; this is a shortcoming of sklearn\n\nCoefficient of engine size =  [[12988.28102112]]\nIntercept =  [-4122.03574424]\n\n\n\n# Prediction\n\n# Again, separate the predictor(s) and the response of interest\nX_test = test[['engineSize']]\ny_test = test[['price']].to_numpy() # Easier to handle with calculations as np array\n\ny_pred = model.predict(X_test)\n\n# Evaluate\nmodel_rmse = np.sqrt(np.mean((y_pred - y_test)**2)) # RMSE\nmodel_mae = np.mean(np.abs(y_pred - y_test)) # MAE\n\nprint('Test RMSE: ', model_rmse)\n\nTest RMSE:  12995.106451548696\n\n\n\n# Easier way to calculate metrics with sklearn tools\n\n# Note that we have imported the functions 'mean_squared_error' and 'mean_absolute_error'\n# from the sklearn.metrics module (check top of the code)\n\nmodel_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\nmodel_mae = mean_absolute_error(y_test,y_pred)\nprint('Test RMSE: ', model_rmse)\nprint('Test MAE: ', model_mae)\n\nTest RMSE:  12995.106451548696\nTest MAE:  9411.325912951994\n\n\n\ny_pred_train = model.predict(X_train)\nprint('Train R-squared:', r2_score(y_train, y_pred_train))\nprint('Test R-squared:', r2_score(y_test, y_pred))\n\nTrain R-squared: 0.39049842625794573\nTest R-squared: 0.3869900378620146\n\n\nNote: Why did we repeat the same task in two different libraries?\n\nstatsmodels and sklearn have different advantages - we will use both for our purposes\n\nstatsmodels returns a lot of statistical output, which is very helpful for inference (coming up next) but it has a limited variety of models.\nWith statsmodels, you may have columns in your DataFrame in addition to predictors and response, while with sklearn you need to make separate objects consisting of only the predictors and the response.\nsklearn includes many models (Lasso and Ridge this quarter, many others next quarter) and helpful tools/functions (like metrics) that statsmodels does not but it does not have any inference tools.\n\n\n\n\n1.1.3 Training with statsmodels.api\nEarlier we had used the statsmodels.formula.api module, where we had to put the regression model as a formula. We can also use the statsmodels.api module to develop a regression model. The syntax of training a model with the OLS() function in this module is similar to that of sklearn’s LinearRegression() function. However, the order in which the predictors and response are specified is different. The formula-style syntax of the statsmodels.formula.api module is generally preferred. However, depending on the situation, the OLS() syntax of statsmodels.api may be preferred.\nNote that you will manually need to add the predictor (a column of ones) corresponding to the intercept to train the model with this method.\n\n# Create the model as an object\n\n# Train the model - separate the predictor(s) and the response for this!\nX_train = train[['engineSize']]\ny_train = train[['price']]\n\nX_train_with_intercept = np.concatenate((np.ones(X_train.shape[0]).reshape(-1,1), X_train), axis = 1)\n\nmodel = sm.OLS(y_train, X_train_with_intercept).fit()\n    \n# Return the parameters\nprint(model.params) \n\nconst    -4122.035744\nx1       12988.281021\ndtype: float64\n\n\nThe model summary and all other attributes and methods of the model object are the same as that with the object created using the statsmodels.formula.api module.\n\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.390\n\n\nModel:\nOLS\nAdj. R-squared:\n0.390\n\n\nMethod:\nLeast Squares\nF-statistic:\n3177.\n\n\nDate:\nMon, 08 Jan 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n11:17:55\nLog-Likelihood:\n-53949.\n\n\nNo. Observations:\n4960\nAIC:\n1.079e+05\n\n\nDf Residuals:\n4958\nBIC:\n1.079e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nconst\n-4122.0357\n522.260\n-7.893\n0.000\n-5145.896\n-3098.176\n\n\nx1\n1.299e+04\n230.450\n56.361\n0.000\n1.25e+04\n1.34e+04\n\n\n\n\n\n\nOmnibus:\n1271.986\nDurbin-Watson:\n0.517\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n6490.719\n\n\nSkew:\n1.137\nProb(JB):\n0.00\n\n\nKurtosis:\n8.122\nCond. No.\n7.64\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec2_MultipleLinearRegression.html",
    "href": "Lec2_MultipleLinearRegression.html",
    "title": "2  Multiple Linear Regression",
    "section": "",
    "text": "2.1 Multiple Linear Regression\n# importing libraries \nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nDevelop a multiple linear regression model that predicts car price based on engine size, year, mileage, and mpg. Datasets to be used: Car_features_train.csv, Car_prices_train.csv\n# Reading datasets\ntrainf = pd.read_csv('./Datasets/Car_features_train.csv')\ntrainp = pd.read_csv('./Datasets/Car_prices_train.csv')\ntrain = pd.merge(trainf,trainp)\ntrain.head()\n\n\n\n\n\n\n\n\ncarID\nbrand\nmodel\nyear\ntransmission\nmileage\nfuelType\ntax\nmpg\nengineSize\nprice\n\n\n\n\n0\n18473\nbmw\n6 Series\n2020\nSemi-Auto\n11\nDiesel\n145\n53.3282\n3.0\n37980\n\n\n1\n15064\nbmw\n6 Series\n2019\nSemi-Auto\n10813\nDiesel\n145\n53.0430\n3.0\n33980\n\n\n2\n18268\nbmw\n6 Series\n2020\nSemi-Auto\n6\nDiesel\n145\n53.4379\n3.0\n36850\n\n\n3\n18480\nbmw\n6 Series\n2017\nSemi-Auto\n18895\nDiesel\n145\n51.5140\n3.0\n25998\n\n\n4\n18492\nbmw\n6 Series\n2015\nAutomatic\n62953\nDiesel\n160\n51.4903\n3.0\n18990",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec2_MultipleLinearRegression.html#multiple-linear-regression",
    "href": "Lec2_MultipleLinearRegression.html#multiple-linear-regression",
    "title": "2  Multiple Linear Regression",
    "section": "",
    "text": "2.1.1 Training the model\n\n#Using the ols function to create an ols object. 'ols' stands for 'Ordinary least squares'\nols_object = smf.ols(formula = 'price~year+mileage+mpg+engineSize', data = train)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.660\n\n\nModel:\nOLS\nAdj. R-squared:\n0.660\n\n\nMethod:\nLeast Squares\nF-statistic:\n2410.\n\n\nDate:\nMon, 29 Jan 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n03:10:20\nLog-Likelihood:\n-52497.\n\n\nNo. Observations:\n4960\nAIC:\n1.050e+05\n\n\nDf Residuals:\n4955\nBIC:\n1.050e+05\n\n\nDf Model:\n4\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-3.661e+06\n1.49e+05\n-24.593\n0.000\n-3.95e+06\n-3.37e+06\n\n\nyear\n1817.7366\n73.751\n24.647\n0.000\n1673.151\n1962.322\n\n\nmileage\n-0.1474\n0.009\n-16.817\n0.000\n-0.165\n-0.130\n\n\nmpg\n-79.3126\n9.338\n-8.493\n0.000\n-97.620\n-61.006\n\n\nengineSize\n1.218e+04\n189.969\n64.107\n0.000\n1.18e+04\n1.26e+04\n\n\n\n\n\n\nOmnibus:\n2450.973\nDurbin-Watson:\n0.541\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n31060.548\n\n\nSkew:\n2.045\nProb(JB):\n0.00\n\n\nKurtosis:\n14.557\nCond. No.\n3.83e+07\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 3.83e+07. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nThe model equation is: estimated car price = -3.661e6 + 1818 * year -0.15 * mileage - 79.31 * mpg + 12180 * engineSize\nThe procedure to fit the model using sklearn will be similar to that in simple linear regression.\n\nmodel = LinearRegression()\n\nX_train = train[['year','engineSize','mpg','mileage']] # Slice out the predictors\ny_train = train[['price']]\n\nmodel.fit(X_train,y_train)\n\n\n\n2.1.2 Hypothesis test for a relationship between the response and a subset of predictors\nLet us test the hypothesis if there is relationship between car price and the set of predictors: mpg and year.\n\nhypothesis = '(mpg = 0, year = 0)'     \n    \nmodel.f_test(hypothesis) # the F test of these two predictors is stat. sig.\n\n&lt;class 'statsmodels.stats.contrast.ContrastResults'&gt;\n&lt;F test: F=325.9206432972666, p=1.0499509223096256e-133, df_denom=4.96e+03, df_num=2&gt;\n\n\nAs the \\(p\\)-value is low, we reject the null hypothesis, i.e., at least one of the predictors among mpg and year has a statistically significant relationship with car price.\nPredict the car price for the cars in the test dataset. Datasets to be used: Car_features_test.csv, Car_prices_test.csv\n\ntestf = pd.read_csv('./Datasets/Car_features_test.csv')\ntestp = pd.read_csv('./Datasets/Car_prices_test.csv')\n\n\n\n2.1.3 Prediction\n\npred_price = model.predict(testf)\n\nMake a visualization that compares the predicted car prices with the actual car prices\n\nsns.set(font_scale=1.25)\nsns.scatterplot(x = testp.price, y = pred_price, color = 'orange')\n#In case of a perfect prediction, all the points must lie on the line x = y.\nax = sns.lineplot(x = [0,testp.price.max()], y = [0,testp.price.max()],color='blue') #Plotting the line x = y.\nplt.xlabel('Actual price')\nplt.ylabel('Predicted price')\nplt.ylim([-10000, 160000])\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('${x:,.0f}')\nplt.xticks(rotation=20);\n\n\n\n\n\n\n\n\nThe prediction looks better as compared to the one with simple linear regression. This is because we have four predictors to help explain the variation in car price, instead of just one in the case of simple linear regression. Also, all the predictors have a significant relationship with price as evident from their p-values. Thus, all four of them are contributing in explaining the variation. Note the higher values of \\(R^2\\) as compared to the one in the case of simple linear regression.\nWhat is the RMSE of the predicted car price?\n\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n9956.82497993548\n\n\nWhat is the residual standard error based on the training data?\n\nnp.sqrt(model.mse_resid)\n\n9563.74782917604\n\n\n\ntrainp.describe()\n\n\n\n\n\n\n\n\ncarID\nprice\n\n\n\n\ncount\n4960.000000\n4960.000000\n\n\nmean\n15832.446169\n23469.943750\n\n\nstd\n2206.717006\n16406.714563\n\n\nmin\n12002.000000\n450.000000\n\n\n25%\n13929.250000\n12000.000000\n\n\n50%\n15840.000000\n18999.000000\n\n\n75%\n17765.750000\n30335.750000\n\n\nmax\n19629.000000\n145000.000000\n\n\n\n\n\n\n\n\nsns.scatterplot(x = model.fittedvalues, y=model.resid,color = 'orange')\nax = sns.lineplot(x = [pred_price.min(),pred_price.max()],y = [0,0],color = 'blue')\nplt.xlabel('Predicted price')\nplt.ylabel('Residual')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('${x:,.0f}')\nplt.xticks(rotation=20);\n\n\n\n\n\n\n\n\n\n\n2.1.4 Effect of adding noisy predictors on \\(R^2\\)\nWill the explained variation (R-squared) in car price always increase if we add a variable?\nShould we keep on adding variables as long as the explained variation (R-squared) is increasing?\n\n#Using the ols function to create an ols object. 'ols' stands for 'Ordinary least squares'\nnp.random.seed(1)\ntrain['rand_col'] = np.random.rand(train.shape[0])\nols_object = smf.ols(formula = 'price~year+mileage+mpg+engineSize+rand_col', data = train)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.661\n\n\nModel:\nOLS\nAdj. R-squared:\n0.660\n\n\nMethod:\nLeast Squares\nF-statistic:\n1928.\n\n\nDate:\nTue, 27 Dec 2022\nProb (F-statistic):\n0.00\n\n\nTime:\n01:07:38\nLog-Likelihood:\n-52497.\n\n\nNo. Observations:\n4960\nAIC:\n1.050e+05\n\n\nDf Residuals:\n4954\nBIC:\n1.050e+05\n\n\nDf Model:\n5\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-3.662e+06\n1.49e+05\n-24.600\n0.000\n-3.95e+06\n-3.37e+06\n\n\nyear\n1818.1672\n73.753\n24.652\n0.000\n1673.578\n1962.756\n\n\nmileage\n-0.1474\n0.009\n-16.809\n0.000\n-0.165\n-0.130\n\n\nmpg\n-79.2837\n9.338\n-8.490\n0.000\n-97.591\n-60.976\n\n\nengineSize\n1.218e+04\n189.972\n64.109\n0.000\n1.18e+04\n1.26e+04\n\n\nrand_col\n451.1226\n471.897\n0.956\n0.339\n-474.004\n1376.249\n\n\n\n\n\n\nOmnibus:\n2451.728\nDurbin-Watson:\n0.541\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n31040.331\n\n\nSkew:\n2.046\nProb(JB):\n0.00\n\n\nKurtosis:\n14.552\nCond. No.\n3.83e+07\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 3.83e+07. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nAdding a variable with random values to the model (rand_col) increased the explained variation (\\(R^2\\)). This is because the model has one more parameter to tune to reduce the residual squared error \\((RSS)\\). However, the \\(p\\)-value of rand_col suggests that its coefficient is zero. Thus, using the model with rand_col may give poorer performance on unknown data, as compared to the model without rand_col. This implies that it is not a good idea to blindly add variables in the model to increase \\(R^2\\).",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Lec3_VariableTransformations_and_Interactions.html",
    "href": "Lec3_VariableTransformations_and_Interactions.html",
    "title": "3  Variable interactions and transformations",
    "section": "",
    "text": "3.1 Variable interactions\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\ntrainf = pd.read_csv('./Datasets/Car_features_train.csv')\ntrainp = pd.read_csv('./Datasets/Car_prices_train.csv')\ntestf = pd.read_csv('./Datasets/Car_features_test.csv')\ntestp = pd.read_csv('./Datasets/Car_prices_test.csv')\ntrain = pd.merge(trainf,trainp)\ntest = pd.merge(testf,testp)\ntrain.head()\n\n\n\n\n\n\n\n\ncarID\nbrand\nmodel\nyear\ntransmission\nmileage\nfuelType\ntax\nmpg\nengineSize\nprice\n\n\n\n\n0\n18473\nbmw\n6 Series\n2020\nSemi-Auto\n11\nDiesel\n145\n53.3282\n3.0\n37980\n\n\n1\n15064\nbmw\n6 Series\n2019\nSemi-Auto\n10813\nDiesel\n145\n53.0430\n3.0\n33980\n\n\n2\n18268\nbmw\n6 Series\n2020\nSemi-Auto\n6\nDiesel\n145\n53.4379\n3.0\n36850\n\n\n3\n18480\nbmw\n6 Series\n2017\nSemi-Auto\n18895\nDiesel\n145\n51.5140\n3.0\n25998\n\n\n4\n18492\nbmw\n6 Series\n2015\nAutomatic\n62953\nDiesel\n160\n51.4903\n3.0\n18990\nUntil now, we have assumed that the association between a predictor \\(X_j\\) and response \\(Y\\) does not depend on the value of other predictors. For example, the multiple linear regression model that we developed in Chapter 2 assumes that the average increase in price associated with a unit increase in engineSize is always $12,180, regardless of the value of other predictors. However, this assumption may be incorrect.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variable interactions and transformations</span>"
    ]
  },
  {
    "objectID": "Lec3_VariableTransformations_and_Interactions.html#variable-interactions",
    "href": "Lec3_VariableTransformations_and_Interactions.html#variable-interactions",
    "title": "3  Variable interactions and transformations",
    "section": "",
    "text": "3.1.1 Variable interaction between continuous predictors\nWe can relax this assumption by considering another predictor, called an interaction term. Let us assume that the average increase in price associated with a one-unit increase in engineSize depends on the model year of the car. In other words, there is an interaction between engineSize and year. This interaction can be included as a predictor, which is the product of engineSize and year. Note that there are several possible interactions that we can consider. Here the interaction between engineSize and year is just an example.\n\n#Considering interaction between engineSize and year\nols_object = smf.ols(formula = 'price~year*engineSize+mileage+mpg', data = train)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.682\n\n\nModel:\nOLS\nAdj. R-squared:\n0.681\n\n\nMethod:\nLeast Squares\nF-statistic:\n2121.\n\n\nDate:\nTue, 24 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n15:28:11\nLog-Likelihood:\n-52338.\n\n\nNo. Observations:\n4960\nAIC:\n1.047e+05\n\n\nDf Residuals:\n4954\nBIC:\n1.047e+05\n\n\nDf Model:\n5\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n5.606e+05\n2.74e+05\n2.048\n0.041\n2.4e+04\n1.1e+06\n\n\nyear\n-275.3833\n135.695\n-2.029\n0.042\n-541.405\n-9.361\n\n\nengineSize\n-1.796e+06\n9.97e+04\n-18.019\n0.000\n-1.99e+06\n-1.6e+06\n\n\nyear:engineSize\n896.7687\n49.431\n18.142\n0.000\n799.861\n993.676\n\n\nmileage\n-0.1525\n0.008\n-17.954\n0.000\n-0.169\n-0.136\n\n\nmpg\n-84.3417\n9.048\n-9.322\n0.000\n-102.079\n-66.604\n\n\n\n\n\n\nOmnibus:\n2330.413\nDurbin-Watson:\n0.524\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n29977.437\n\n\nSkew:\n1.908\nProb(JB):\n0.00\n\n\nKurtosis:\n14.423\nCond. No.\n7.66e+07\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 7.66e+07. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nNote that the R-squared has increased as compared to the model in Chapter 2 since we added a predictor.\nThe model equation is:\n\\[\\begin{equation}\nprice = \\beta_0 + \\beta_1*year + \\beta_2*engineSize + \\beta_3*(year * engineSize) + \\beta4*mileage + \\beta_5*mpg,\n\\end{equation}\\]or\n\\[\\begin{equation}\nprice = \\beta_0 + \\beta_1*year + (\\beta_2+\\beta_3*year)*engineSize + \\beta4*mileage + \\beta_5*mpg,\n\\end{equation}\\]or\n\\[\\begin{equation}\nprice = \\beta_0 + \\beta_1*year + \\tilde \\beta*engineSize + \\beta4*mileage + \\beta_5*mpg,\n\\end{equation}\\]\nSince \\(\\tilde \\beta\\) is a function of year, the association between engineSize and price is no longer a constant. A change in the value of year will change the association between price and engineSize.\nSubstituting the values of the coefficients:\nprice = 5.606e5 - 275.3833year + (-1.796e6+896.7687year)engineSize -0.1525mileage -84.3417mpg\nThus, for cars launched in the year 2010, the average increase in price for one liter increase in engine size is -1.796e6 + 896.7687 * 2010 \\(\\approx\\) \\$6,500, assuming all the other predictors are constant. However, for cars launched in the year 2020, the average increase in price for one liter increase in engine size is -1.796e6 + 896.7687*2020 \\(\\approx\\) \\$15,500 , assuming all the other predictors are constant.\nSimilarly, the equation can be re-arranged as:\nprice = 5.606e5 +(-275.3833+896.7687engineSize)year -1.796e6engineSize -0.1525mileage -84.3417*mpg\nThus, for cars with an engine size of 2 litres, the average increase in price for a one year newer model is -275.3833+896.7687 * 2 \\(\\approx\\) \\$1500, assuming all the other predictors are constant. However, for cars with an engine size of 3 litres, the average increase in price for a one year newer model is -275.3833+896.7687 * 3 \\(\\approx\\) \\$2400, assuming all the other predictors are constant.\n\n#Computing the RMSE of the model with the interaction term\npred_price = model.predict(testf)\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n9423.598872501092\n\n\nNote that the RMSE is lower than that of the model in Chapter 2. This is because the interaction term between engineSize and year is significant and relaxes the assumption of constant association between price and engine size, and between price and year. This added flexibility makes the model better fit the data. Caution: Too much flexibility may lead to overfitting!\nNote that interaction terms corresponding to other variable pairs, and higher order interaction terms (such as those containing 3 or 4 variables) may also be significant and improve the model fit & thereby the prediction accuracy of the model.\n\n\n3.1.2 Including qualitative predictors in the model\nLet us develop a model for predicting price based on engineSize and the qualitative predictor transmission.\n\n#checking the distribution of values of transmission\ntrain.transmission.value_counts()\n\nManual       1948\nAutomatic    1660\nSemi-Auto    1351\nOther           1\nName: transmission, dtype: int64\n\n\nNote that the Other category of the variable transmission contains only a single observation, which is likely to be insufficient to train the model. We’ll remove that observation from the training data. Another option may be to combine the observation in the Other category with the nearest category, and keep it in the data.\n\ntrain_updated = train[train.transmission!='Other']\n\n\nols_object = smf.ols(formula = 'price ~ engineSize + transmission', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.459\n\n\nModel:\nOLS\nAdj. R-squared:\n0.458\n\n\nMethod:\nLeast Squares\nF-statistic:\n1400.\n\n\nDate:\nTue, 24 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n15:28:21\nLog-Likelihood:\n-53644.\n\n\nNo. Observations:\n4959\nAIC:\n1.073e+05\n\n\nDf Residuals:\n4955\nBIC:\n1.073e+05\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n3042.6765\n661.190\n4.602\n0.000\n1746.451\n4338.902\n\n\ntransmission[T.Manual]\n-6770.6165\n442.116\n-15.314\n0.000\n-7637.360\n-5903.873\n\n\ntransmission[T.Semi-Auto]\n4994.3112\n442.989\n11.274\n0.000\n4125.857\n5862.765\n\n\nengineSize\n1.023e+04\n247.485\n41.323\n0.000\n9741.581\n1.07e+04\n\n\n\n\n\n\nOmnibus:\n1575.518\nDurbin-Watson:\n0.579\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n11006.609\n\n\nSkew:\n1.334\nProb(JB):\n0.00\n\n\nKurtosis:\n9.793\nCond. No.\n11.4\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nNote that there is no coefficient for the Automatic level of the variable Transmission. If a car doesn’t have Manual or Semi-Automatic transmission, then it has an Automatic transmission. Thus, the coefficient of Automatic will be redundant, and the dummy variable corresponding to Automatic transmission is dropped from the model.\nThe level of the categorical variable that is dropped from the model is called the baseline level. Here Automatic transmission is the baseline level. The coefficients of other levels of transmission should be interpreted with respect to the baseline level.\nQ: Interpret the intercept term\nAns: For the hypothetical scenario of a car with zero engine size and Automatic transmission, the estimated mean car price is \\(\\approx\\) \\$3042.\nQ: Interpret the coefficient of transmission[T.Manual]\nAns: The estimated mean price of a car with manual transmission is \\(\\approx\\) \\$6770 less than that of a car with Automatic transmission.\nLet us visualize the developed model.\n\n#Visualizing the developed model\nplt.rcParams[\"figure.figsize\"] = (9,6)\nsns.set(font_scale = 1.3)\nx = np.linspace(train_updated.engineSize.min(),train_updated.engineSize.max(),100)\nax = sns.lineplot(x = x, y = model.params['engineSize']*x+model.params['Intercept'], color = 'red')\nsns.lineplot(x = x, y = model.params['engineSize']*x+model.params['Intercept']+model.params['transmission[T.Semi-Auto]'], color = 'blue')\nsns.lineplot(x = x, y = model.params['engineSize']*x+model.params['Intercept']+model.params['transmission[T.Manual]'], color = 'green')\nplt.legend(labels=[\"Automatic\",\"Semi-Automatic\", \"Manual\"])\nplt.xlabel('Engine size (in litre)')\nplt.ylabel('Predicted car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\n\n\n\n\n\n\n\n\nBased on the developed model, for a given engine size, the car with a semi-automatic transmission is estimated to be the most expensive on average, while the car with a manual transmission is estimated to be the least expensive on average.\nChanging the baseline level: By default, the baseline level is chosen as the one that comes first if the levels are arranged in alphabetical order. However, you can change the baseline level by specifying one explicitly.\nInternally, statsmodels uses the patsy package to convert formulas and data to the matrices that are used in model fitting. You may refer to this section in the patsy documentation to specify a particular level of the categorical variable as the baseline.\nFor example, suppose we wish to change the baseline level to Manual transmission. We can specify this in the formula as follows:\n\nols_object = smf.ols(formula = 'price~engineSize+C(transmission, Treatment(\"Manual\"))', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.459\n\n\nModel:\nOLS\nAdj. R-squared:\n0.458\n\n\nMethod:\nLeast Squares\nF-statistic:\n1400.\n\n\nDate:\nTue, 24 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n15:28:39\nLog-Likelihood:\n-53644.\n\n\nNo. Observations:\n4959\nAIC:\n1.073e+05\n\n\nDf Residuals:\n4955\nBIC:\n1.073e+05\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-3727.9400\n492.917\n-7.563\n0.000\n-4694.275\n-2761.605\n\n\nC(transmission, Treatment(\"Manual\"))[T.Automatic]\n6770.6165\n442.116\n15.314\n0.000\n5903.873\n7637.360\n\n\nC(transmission, Treatment(\"Manual\"))[T.Semi-Auto]\n1.176e+04\n473.110\n24.867\n0.000\n1.08e+04\n1.27e+04\n\n\nengineSize\n1.023e+04\n247.485\n41.323\n0.000\n9741.581\n1.07e+04\n\n\n\n\n\n\nOmnibus:\n1575.518\nDurbin-Watson:\n0.579\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n11006.609\n\n\nSkew:\n1.334\nProb(JB):\n0.00\n\n\nKurtosis:\n9.793\nCond. No.\n8.62\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n3.1.3 Including qualitative predictors and their interaction with continuous predictors in the model\nNote that the qualitative predictor leads to fitting 3 parallel lines to the data, as there are 3 categories.\nHowever, note that we have made the constant association assumption. The fact that the lines are parallel means that the average increase in car price for one litre increase in engine size does not depend on the type of transmission. This represents a potentially serious limitation of the model, since in fact a change in engine size may have a very different association on the price of an automatic car versus a semi-automatic or manual car.\nThis limitation can be addressed by adding an interaction variable, which is the product of engineSize and the dummy variables for semi-automatic and manual transmissions.\n\n#Using the ols function to create an ols object. 'ols' stands for 'Ordinary least squares'\nols_object = smf.ols(formula = 'price~engineSize*transmission', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.479\n\n\nModel:\nOLS\nAdj. R-squared:\n0.478\n\n\nMethod:\nLeast Squares\nF-statistic:\n909.9\n\n\nDate:\nSun, 22 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n22:55:55\nLog-Likelihood:\n-53550.\n\n\nNo. Observations:\n4959\nAIC:\n1.071e+05\n\n\nDf Residuals:\n4953\nBIC:\n1.072e+05\n\n\nDf Model:\n5\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n3754.7238\n895.221\n4.194\n0.000\n1999.695\n5509.753\n\n\ntransmission[T.Manual]\n1768.5856\n1294.071\n1.367\n0.172\n-768.366\n4305.538\n\n\ntransmission[T.Semi-Auto]\n-5282.7164\n1416.472\n-3.729\n0.000\n-8059.628\n-2505.805\n\n\nengineSize\n9928.6082\n354.511\n28.006\n0.000\n9233.610\n1.06e+04\n\n\nengineSize:transmission[T.Manual]\n-5285.9059\n646.175\n-8.180\n0.000\n-6552.695\n-4019.117\n\n\nengineSize:transmission[T.Semi-Auto]\n4162.2428\n552.597\n7.532\n0.000\n3078.908\n5245.578\n\n\n\n\n\n\nOmnibus:\n1379.846\nDurbin-Watson:\n0.622\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n9799.471\n\n\nSkew:\n1.139\nProb(JB):\n0.00\n\n\nKurtosis:\n9.499\nCond. No.\n30.8\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe model equation for the model with interactions is:\nAutomatic transmission: price = 3754.7238 + 9928.6082 * engineSize,\nSemi-Automatic transmission: price = 3754.7238 + 9928.6082 * engineSize + (-5282.7164+4162.2428*engineSize),\n\nManual transmission: price = 3754.7238 + 9928.6082 * engineSize +(1768.5856-5285.9059 * engineSize),\nor\nAutomatic transmission: price = 3754.7238 + 9928.6082 * engineSize,\nSemi-Automatic transmission: price = -1527 + 7046 * engineSize,\nManual transmission: price = 5523 + 4642 * engineSize\nQ: Interpret the coefficient of manual tranmission, i.e., the coefficient of transmission[T.Manual].\nA: For a hypothetical scenario of zero engine size, the estimated mean price of a car with Manual transmission is \\(\\approx\\) \\$1768 more than the estimated mean price of a car with Automatic transmission.\nQ: Interpret the coefficient of the interaction between engine size and manual transmission, i.e., the coefficient of engineSize:transmission[T.Manual].\nA: For a unit (or a litre) increase in engineSize , the increase in estimated mean price of a car with Manual transmission is \\(\\approx\\) \\$5285 less than the increase in estimated mean price of a car with Automatic transmission.\n\n#Visualizing the developed model with interaction terms\nplt.rcParams[\"figure.figsize\"] = (9,6)\nsns.set(font_scale = 1.3)\nx = np.linspace(train_updated.engineSize.min(),train_updated.engineSize.max(),100)\nax = sns.lineplot(x = x, y = model.params['engineSize']*x+model.params['Intercept'], label='Automatic', color = 'red')\nplt.plot(x, (model.params['engineSize']+model.params['engineSize:transmission[T.Semi-Auto]'])*x+model.params['Intercept']+model.params['transmission[T.Semi-Auto]'], '-b', label='Semi-Automatic')\nplt.plot(x, (model.params['engineSize']+model.params['engineSize:transmission[T.Manual]'])*x+model.params['Intercept']+model.params['transmission[T.Manual]'], '-g', label='Manual')\nplt.legend(loc='upper left')\nplt.xlabel('Engine size (in litre)')\nplt.ylabel('Predicted car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\n\n\n\n\n\n\n\n\nNote the interaction term adds flexibility to the model.\nThe slope of the regression line for semi-automatic cars is the largest. This suggests that increase in engine size is associated with a higher increase in car price for semi-automatic cars, as compared to other cars.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variable interactions and transformations</span>"
    ]
  },
  {
    "objectID": "Lec3_VariableTransformations_and_Interactions.html#variable-transformations",
    "href": "Lec3_VariableTransformations_and_Interactions.html#variable-transformations",
    "title": "3  Variable interactions and transformations",
    "section": "3.2 Variable transformations",
    "text": "3.2 Variable transformations\nSo far we have considered only a linear relationship between the predictors and the response. However, the relationship may be non-linear.\nConsider the regression plot of price on mileage.\n\nax = sns.regplot(x = train_updated.mileage, y =train_updated.price,color = 'orange', line_kws = {'color':'blue'})\nplt.xlabel('Mileage')\nplt.ylabel('Predicted car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('{x:,.0f}')\n\n\n\n\n\n\n\n\n\n#R-squared of the model with just mileage\nmodel = smf.ols('price~mileage', data = train_updated).fit()\nmodel.rsquared\n\n0.22928048993376182\n\n\nFrom the first scatterplot, we see that the relationship between price and mileage doesn’t seem to be linear, as the points do not lie on a straight line. Also, we see the regression line (or the curve), which is the best fit line doesn’t seem to fit the points well. However, price on average seems to decrease with mileage, albeit in a non-linear manner.\n\n3.2.1 Quadratic transformation\nSo, we guess that if we model price as a quadratic function of mileage, the model may better fit the points (or the curve may better fit the points). Let us transform the predictor mileage to include \\(mileage^2\\) (i.e., perform a quadratic transformation on the predictor).\n\n#Including mileage squared as a predictor and developing the model\nols_object = smf.ols(formula = 'price~mileage+I(mileage**2)', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.271\n\n\nModel:\nOLS\nAdj. R-squared:\n0.271\n\n\nMethod:\nLeast Squares\nF-statistic:\n920.6\n\n\nDate:\nSun, 22 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n23:26:05\nLog-Likelihood:\n-54382.\n\n\nNo. Observations:\n4959\nAIC:\n1.088e+05\n\n\nDf Residuals:\n4956\nBIC:\n1.088e+05\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n3.44e+04\n332.710\n103.382\n0.000\n3.37e+04\n3.5e+04\n\n\nmileage\n-0.5662\n0.017\n-33.940\n0.000\n-0.599\n-0.534\n\n\nI(mileage ** 2)\n2.629e-06\n1.56e-07\n16.813\n0.000\n2.32e-06\n2.94e-06\n\n\n\n\n\n\nOmnibus:\n2362.973\nDurbin-Watson:\n0.325\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n22427.952\n\n\nSkew:\n2.052\nProb(JB):\n0.00\n\n\nKurtosis:\n12.576\nCond. No.\n4.81e+09\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 4.81e+09. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nNote that in the formula specified within the ols() function, the I() operator isolates or insulates the contents within I(…) from the regular formula operators. Without the I() operator, mileage**2 will be treated as the interaction of mileage with itself, which is mileage. Thus, to add the square of mileage as a separate predictor, we need to use the I() operator.\nLet us visualize the model fit with the quadratic transformation of the predictor - mileage.\n\n#Visualizing the regression line with the model consisting of the quadratic transformation of the predictor - mileage\npred_price = model.predict(train_updated)\nax = sns.scatterplot(x = 'mileage', y = 'price', data = train_updated, color = 'orange')\nsns.lineplot(x = train_updated.mileage, y = pred_price, color = 'blue')\nplt.xlabel('Mileage')\nplt.ylabel('Predicted car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('{x:,.0f}')\n\n\n\n\n\n\n\n\nThe above model seems to better fit the data (as compared to the model without transformation) at least upto mileage around 125,000. The \\(R^2\\) of the model with the quadratic transformation of mileage is also higher than that of the model without transformation indicating a better fit.\n\n\n3.2.2 Cubic transformation\nLet us see if a cubic transformation of mileage can further improve the model fit.\n\n#Including mileage squared and mileage cube as predictors and developing the model\nols_object = smf.ols(formula = 'price~mileage+I(mileage**2)+I(mileage**3)', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.283\n\n\nModel:\nOLS\nAdj. R-squared:\n0.283\n\n\nMethod:\nLeast Squares\nF-statistic:\n652.3\n\n\nDate:\nSun, 22 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n23:33:27\nLog-Likelihood:\n-54340.\n\n\nNo. Observations:\n4959\nAIC:\n1.087e+05\n\n\nDf Residuals:\n4955\nBIC:\n1.087e+05\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n3.598e+04\n371.926\n96.727\n0.000\n3.52e+04\n3.67e+04\n\n\nmileage\n-0.7742\n0.028\n-27.634\n0.000\n-0.829\n-0.719\n\n\nI(mileage ** 2)\n6.875e-06\n4.87e-07\n14.119\n0.000\n5.92e-06\n7.83e-06\n\n\nI(mileage ** 3)\n-1.823e-11\n1.98e-12\n-9.199\n0.000\n-2.21e-11\n-1.43e-11\n\n\n\n\n\n\nOmnibus:\n2380.788\nDurbin-Watson:\n0.321\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n23039.307\n\n\nSkew:\n2.065\nProb(JB):\n0.00\n\n\nKurtosis:\n12.719\nCond. No.\n7.73e+14\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 7.73e+14. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\n\n#Visualizing the model with the cubic transformation of mileage\npred_price = model.predict(train_updated)\nax = sns.scatterplot(x = 'mileage', y = 'price', data = train_updated, color = 'orange')\nsns.lineplot(x = train_updated.mileage, y = pred_price, color = 'blue')\nplt.xlabel('Mileage')\nplt.ylabel('Predicted car price')\nax.yaxis.set_major_formatter('${x:,.0f}')\nax.xaxis.set_major_formatter('{x:,.0f}')\n\n\n\n\n\n\n\n\nNote that the model fit with the cubic transformation of mileage seems slightly better as compared to the models with the quadratic transformation, and no transformation of mileage, for mileage up to 180k. However, the model should not be used to predict car prices of cars with a mileage higher than 180k.\nLet’s update the model created earlier (in the beginning of this chapter) to include the transformed predictor.\n\n#Model with an interaction term and a variable transformation term\nols_object = smf.ols(formula = 'price~year*engineSize+mileage+mpg+I(mileage**2)', data = train_updated)\nmodel = ols_object.fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nprice\nR-squared:\n0.702\n\n\nModel:\nOLS\nAdj. R-squared:\n0.702\n\n\nMethod:\nLeast Squares\nF-statistic:\n1947.\n\n\nDate:\nSun, 22 Jan 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n23:42:13\nLog-Likelihood:\n-52162.\n\n\nNo. Observations:\n4959\nAIC:\n1.043e+05\n\n\nDf Residuals:\n4952\nBIC:\n1.044e+05\n\n\nDf Model:\n6\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n1.53e+06\n2.7e+05\n5.671\n0.000\n1e+06\n2.06e+06\n\n\nyear\n-755.7419\n133.791\n-5.649\n0.000\n-1018.031\n-493.453\n\n\nengineSize\n-2.022e+06\n9.72e+04\n-20.803\n0.000\n-2.21e+06\n-1.83e+06\n\n\nyear:engineSize\n1008.6993\n48.196\n20.929\n0.000\n914.215\n1103.184\n\n\nmileage\n-0.3548\n0.014\n-25.973\n0.000\n-0.382\n-0.328\n\n\nmpg\n-54.7450\n8.896\n-6.154\n0.000\n-72.185\n-37.305\n\n\nI(mileage ** 2)\n1.926e-06\n1.04e-07\n18.536\n0.000\n1.72e-06\n2.13e-06\n\n\n\n\n\n\nOmnibus:\n2355.448\nDurbin-Watson:\n0.562\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n38317.404\n\n\nSkew:\n1.857\nProb(JB):\n0.00\n\n\nKurtosis:\n16.101\nCond. No.\n6.40e+12\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 6.4e+12. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nNote that the R-squared has increased as compared to the model with just the interaction term.\n\n#Computing RMSE on test data\npred_price = model.predict(testf)\nnp.sqrt(((testp.price - pred_price)**2).mean())\n\n9074.494088619422\n\n\nNote that the prediction accuracy of the model has further increased, as the RMSE has reduced. The transformed predictor is statistically significant and provides additional flexibility to better capture the trend in the data, leading to an increase in prediction accuracy.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variable interactions and transformations</span>"
    ]
  },
  {
    "objectID": "Lec3_VariableTransformations_and_Interactions.html#polynomialfeatures",
    "href": "Lec3_VariableTransformations_and_Interactions.html#polynomialfeatures",
    "title": "3  Variable interactions and transformations",
    "section": "3.3 PolynomialFeatures()",
    "text": "3.3 PolynomialFeatures()\nThe function PolynomialFeatures() from the sklearn library can be used to generate a predictor matrix that includes all interactions and transformations upto a degree d.\n\nX_train = train[['mileage', 'engineSize', 'year', 'mpg']]\ny_train = train[['price']]\nX_test = test[['mileage', 'engineSize', 'year', 'mpg']]\ny_test = test[['price']]\n\n\n3.3.1 Generating polynomial features\nLet us generate polynomial features upto degree 2. This will include all the two-factor interactions, and all squared terms of degree 2.\n\npoly = PolynomialFeatures(2, include_bias = False) # Create the object - degree is 2\n\n# Generate the polynomial features\nX_train_poly = poly.fit_transform(X_train) \n\nNote that the LinearRegression() function adds the intercept by default (check the fit_intercept argument). Thus, we have put include_bias = False while generating the polynomial features, as we don’t need the intercept. The term bias here refers to the intercept (you will learn about bias in detail in STAT303-3). Another option is to include the intercept while generating the polynomial features, and put fit_intercept = False in the LinearRegression() function.\nBelow are the polynomial features generated by the PolynomialFeatures() functions.\n\npoly.get_feature_names_out()\n\narray(['mileage', 'engineSize', 'year', 'mpg', 'mileage^2',\n       'mileage engineSize', 'mileage year', 'mileage mpg',\n       'engineSize^2', 'engineSize year', 'engineSize mpg', 'year^2',\n       'year mpg', 'mpg^2'], dtype=object)\n\n\n\n\n3.3.2 Fitting the model\n\nmodel = LinearRegression() \nmodel.fit(X_train_poly, y_train) \n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n3.3.3 Testing the model\n\nX_test_poly = poly.fit_transform(X_test)\n\n\n#RMSE\nnp.sqrt(mean_squared_error(y_test, model.predict(X_test_poly)))\n\n8896.175508213777\n\n\nNote that the polynomial features have helped reduced the RMSE further.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variable interactions and transformations</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html",
    "href": "Lec7_logistic_regression.html",
    "title": "4  Logistic regression",
    "section": "",
    "text": "4.1 Theory Behind Logistic Regression\nLogistic regression is the go-to linear classification algorithm for two-class problems. It is easy to implement, easy to understand and gets great results on a wide variety of problems, even when the expectations the method has for your data are violated.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#theory-behind-logistic-regression",
    "href": "Lec7_logistic_regression.html#theory-behind-logistic-regression",
    "title": "4  Logistic regression",
    "section": "",
    "text": "4.1.1 Description\nLogistic regression is named for the function used at the core of the method, the logistic function.\nThe logistic function, also called the Sigmoid function was developed by statisticians to describe properties of population growth in ecology, rising quickly and maxing out at the carrying capacity of the environment. It’s an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1, but never exactly at those limits.\n\\[\\frac{1}{1 + e^{-x}}\\]\n\\(e\\) is the base of the natural logarithms and \\(x\\) is value that you want to transform via the logistic function.\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as sm\n\n\n%matplotlib inline\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\nx = np.linspace(-6, 6, num=1000)\nplt.figure(figsize=(10, 6))\nplt.plot(x, (1 / (1 + np.exp(-x))))\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Sigmoid Function\")\n\nText(0.5, 1.0, 'Sigmoid Function')\n\n\n\n\n\n\n\n\n\nThe logistic regression equation has a very similar representation like linear regression. The difference is that the output value being modelled is binary in nature.\n\\[\\hat{p}=\\frac{e^{\\hat{\\beta_0}+\\hat{\\beta_1}x_1}}{1+e^{\\hat{\\beta_0}+\\hat{\\beta_1}x_1}}\\]\nor\n\\[\\hat{p}=\\frac{1.0}{1.0+e^{-(\\hat{\\beta_0}+\\hat{\\beta_1}x_1)}}\\]\n\\(\\hat{\\beta_0}\\) is the estimated intercept term\n\\(\\hat{\\beta_1}\\) is the estimated coefficient for \\(x_1\\)\n\\(\\hat{p}\\) is the predicted output with real value between 0 and 1. To convert this to binary output of 0 or 1, this would either need to be rounded to an integer value or a cutoff point be provided to specify the class segregation point.\n\n\n4.1.2 Learning the Logistic Regression Model\nThe coefficients (Beta values b) of the logistic regression algorithm must be estimated from your training data. This is done using maximum-likelihood estimation.\nMaximum-likelihood estimation is a common learning algorithm used by a variety of machine learning algorithms, although it does make assumptions about the distribution of your data (more on this when we talk about preparing your data).\nThe best coefficients should result in a model that would predict a value very close to 1 (e.g. male) for the default class and a value very close to 0 (e.g. female) for the other class. The intuition for maximum-likelihood for logistic regression is that a search procedure seeks values for the coefficients (Beta values) that maximize the likelihood of the observed data. In other words, in MLE, we estimate the parameter values (Beta values) which are the most likely to produce that data at hand.\nHere is an analogy to understand the idea behind Maximum Likelihood Estimation (MLE). Let us say, you are listening to a song (data). You are not aware of the singer (parameter) of the song. With just the musical piece at hand, you try to guess the singer (parameter) who you feel is the most likely (MLE) to have sung that song. Your are making a maximum likelihood estimate! Out of all the singers (parameter space) you have chosen them as the one who is the most likely to have sung that song (data).\nWe are not going to go into the math of maximum likelihood. It is enough to say that a minimization algorithm is used to optimize the best values for the coefficients for your training data. This is often implemented in practice using efficient numerical optimization algorithm (like the Quasi-newton method).\nWhen you are learning logistic, you can implement it yourself from scratch using the much simpler gradient descent algorithm.\n\n\n4.1.3 Preparing Data for Logistic Regression\nThe assumptions made by logistic regression about the distribution and relationships in your data are much the same as the assumptions made in linear regression.\nMuch study has gone into defining these assumptions and precise probabilistic and statistical language is used. My advice is to use these as guidelines or rules of thumb and experiment with different data preparation schemes.\nUltimately in predictive modeling machine learning projects you are laser focused on making accurate predictions rather than interpreting the results. As such, you can break some assumptions as long as the model is robust and performs well.\n\nBinary Output Variable: This might be obvious as we have already mentioned it, but logistic regression is intended for binary (two-class) classification problems. It will predict the probability of an instance belonging to the default class, which can be snapped into a 0 or 1 classification.\nRemove Noise: Logistic regression assumes no error in the output variable (y), consider removing outliers and possibly misclassified instances from your training data.\nGaussian Distribution: Logistic regression is a linear algorithm (with a non-linear transform on output). It does assume a linear relationship between the input variables with the output. Data transforms of your input variables that better expose this linear relationship can result in a more accurate model. For example, you can use log, root, Box-Cox and other univariate transforms to better expose this relationship.\nRemove Correlated Inputs: Like linear regression, the model can overfit if you have multiple highly-correlated inputs. Consider calculating the pairwise correlations between all inputs and removing highly correlated inputs.\nFail to Converge: It is possible for the expected likelihood estimation process that learns the coefficients to fail to converge. This can happen if there are many highly correlated inputs in your data or the data is very sparse (e.g. lots of zeros in your input data).",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#logistic-regression-scikit-learn-vs-statsmodels",
    "href": "Lec7_logistic_regression.html#logistic-regression-scikit-learn-vs-statsmodels",
    "title": "4  Logistic regression",
    "section": "4.2 Logistic Regression: Scikit-learn vs Statsmodels",
    "text": "4.2 Logistic Regression: Scikit-learn vs Statsmodels\nPython gives us two ways to do logistic regression. Statsmodels offers modeling from the perspective of statistics. Scikit-learn offers some of the same models from the perspective of machine learning.\nSo we need to understand the difference between statistics and machine learning! Statistics makes mathematically valid inferences about a population based on sample data. Statistics answers the question, “What is the evidence that X is related to Y?” Machine learning has the goal of optimizing predictive accuracy rather than inference. Machine learning answers the question, “Given X, what prediction should we make for Y?”\nLet us see the use of statsmodels for logistic regression. We’ll see scikit-learn later in the course, when we learn methods that focus on prediction.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#training-a-logistic-regression-model",
    "href": "Lec7_logistic_regression.html#training-a-logistic-regression-model",
    "title": "4  Logistic regression",
    "section": "4.3 Training a logistic regression model",
    "text": "4.3 Training a logistic regression model\nRead the data on social network ads. The data shows if the person purchased a product when targeted with an ad on social media. Fit a logistic regression model to predict if a user will purchase the product based on their characteristics such as age, gender and estimated salary.\n\ntrain = pd.read_csv('./Datasets/Social_Network_Ads_train.csv') #Develop the model on train data\ntest = pd.read_csv('./Datasets/Social_Network_Ads_test.csv') #Test the model on test data\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nUser ID\nGender\nAge\nEstimatedSalary\nPurchased\n\n\n\n\n0\n15755018\nMale\n36\n33000\n0\n\n\n1\n15697020\nFemale\n39\n61000\n0\n\n\n2\n15796351\nMale\n36\n118000\n1\n\n\n3\n15665760\nMale\n39\n122000\n1\n\n\n4\n15794661\nFemale\n26\n118000\n0\n\n\n\n\n\n\n\n\n4.3.1 Examining the Distribution of the Target Column\nMake sure our target is not severely imbalanced.\n\ntrain.Purchased.value_counts()\n\n0    194\n1    106\nName: Purchased, dtype: int64\n\n\n\nsns.countplot(x = 'Purchased',data = train);\n\n\n\n\n\n\n\n\nLet us try to fit a linear regression model, instead of logistic regression. We fit a linear regression model to predict probability of purchase based on age.\n\nsns.scatterplot(x = 'Age', y = 'Purchased', data = train, color = 'orange') #Visualizing data\nlm = sm.ols(formula = 'Purchased~Age', data = train).fit() #Developing linear regression model\nsns.lineplot(x = 'Age', y= lm.predict(train), data = train, color = 'blue') #Visualizing model\n\n\n\n\n\n\n\n\nNote the issues with the linear regression model:\n\nThe regression line goes below 0 and over 1. However, probability of purchase must be in [0,1].\nThe linear regression model does not seem to fit the data well.\n\n\n\n4.3.2 Fitting the logistic regression model\nNow, let us fit a logistic regression model to predict probability of purchase based on Age.\n\nsns.scatterplot(x = 'Age', y = 'Purchased', data = train, color = 'orange') #Visualizing data\nlogit_model = sm.logit(formula = 'Purchased~Age', data = train).fit() #Developing logistic regression model\nsns.lineplot(x = 'Age', y= logit_model.predict(train), data = train, color = 'blue') #Visualizing model\n\nOptimization terminated successfully.\n         Current function value: 0.430107\n         Iterations 7\n\n\n\n\n\n\n\n\n\nAs logistic regression uses the sigmoid function, the probability stays in [0,1]. Also, it seems to better fit the points as compared to linear regression.\n\nlogit_model.summary()\n\n\nLogit Regression Results\n\n\nDep. Variable:\nPurchased\nNo. Observations:\n300\n\n\nModel:\nLogit\nDf Residuals:\n298\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nTue, 19 Apr 2022\nPseudo R-squ.:\n0.3378\n\n\nTime:\n16:46:02\nLog-Likelihood:\n-129.03\n\n\nconverged:\nTrue\nLL-Null:\n-194.85\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n1.805e-30\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-7.8102\n0.885\n-8.825\n0.000\n-9.545\n-6.076\n\n\nAge\n0.1842\n0.022\n8.449\n0.000\n0.141\n0.227\n\n\n\n\n\nInterpret the coefficient of age\nFor a unit increase in age, the log odds of purchase increase by 0.18, or the odds of purchase get multiplied by exp(0.18) = 1.2\nIs the increase in probability of purchase constant with a unit increase in age?\nNo, it depends on age.\nIs gender associated with probability of purchase?\n\nlogit_model_gender = sm.logit(formula = 'Purchased~Gender', data = train).fit()\nlogit_model_gender.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.648804\n         Iterations 4\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\nPurchased\nNo. Observations:\n300\n\n\nModel:\nLogit\nDf Residuals:\n298\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nTue, 19 Apr 2022\nPseudo R-squ.:\n0.001049\n\n\nTime:\n16:46:04\nLog-Likelihood:\n-194.64\n\n\nconverged:\nTrue\nLL-Null:\n-194.85\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.5225\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-0.5285\n0.168\n-3.137\n0.002\n-0.859\n-0.198\n\n\nGender[T.Male]\n-0.1546\n0.242\n-0.639\n0.523\n-0.629\n0.319\n\n\n\n\n\nNo, assuming a significance level of \\(\\alpha = 5\\%\\), Gender is not associated with probability of default, as the \\(p\\)-value for Male is greater than 0.05.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#confusion-matrix-and-classification-accuracy",
    "href": "Lec7_logistic_regression.html#confusion-matrix-and-classification-accuracy",
    "title": "4  Logistic regression",
    "section": "4.4 Confusion matrix and classification accuracy",
    "text": "4.4 Confusion matrix and classification accuracy\nA confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class.\n\n#Function to compute confusion matrix and prediction accuracy on training data\ndef confusion_matrix_train(model,cutoff=0.5):\n    # Confusion matrix\n    cm_df = pd.DataFrame(model.pred_table(threshold = cutoff))\n    #Formatting the confusion matrix\n    cm_df.columns = ['Predicted 0', 'Predicted 1'] \n    cm_df = cm_df.rename(index={0: 'Actual 0',1: 'Actual 1'})\n    cm = np.array(cm_df)\n    # Calculate the accuracy\n    accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n    sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n    plt.ylabel(\"Actual Values\")\n    plt.xlabel(\"Predicted Values\")\n    print(\"Classification accuracy = {:.1%}\".format(accuracy))\n\nFind the confusion matrix and classification accuracy of the model with Age as the predictor on training data.\n\ncm = confusion_matrix_train(logit_model)\n\nClassification accuracy = 83.3%\n\n\n\n\n\n\n\n\n\nConfusion matrix:\n\nEach row: actual class\nEach column: predicted class\n\nFirst row: Non-purchasers, the negative class:\n\n181 were correctly classified as Non-purchasers. True negatives.\nRemaining 13 were wrongly classified as Non-purchasers. False positive\n\nSecond row: Purchasers, the positive class:\n\n37 were incorrectly classified as Non-purchasers. False negatives\n69 were correctly classified Purchasers. True positives\n\n\n#Function to compute confusion matrix and prediction accuracy on test data\ndef confusion_matrix_test(data,actual_values,model,cutoff=0.5):\n#Predict the values using the Logit model\n    pred_values = model.predict(data)\n# Specify the bins\n    bins=np.array([0,cutoff,1])\n#Confusion matrix\n    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n    cm_df = pd.DataFrame(cm)\n    cm_df.columns = ['Predicted 0','Predicted 1']\n    cm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n    accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n    sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n    plt.ylabel(\"Actual Values\")\n    plt.xlabel(\"Predicted Values\")\n    print(\"Classification accuracy = {:.1%}\".format(accuracy))\n\nFind the confusion matrix and classification accuracy of the model with Age as the predictor on test data.\n\nconfusion_matrix_test(test,test.Purchased,logit_model)\n\nClassification accuracy = 86.0%\n\n\n\n\n\n\n\n\n\nThe model classifies a bit more accurately on test data as compared to the training data, which is a bit unusual. However, it shows that the model did not overfit on training data.\nInclude EstimatedSalary as a predictor in the above model\n\nlogit_model2 = sm.logit(formula = 'Purchased~Age+EstimatedSalary', data = train).fit()\nlogit_model2.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.358910\n         Iterations 7\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\nPurchased\nNo. Observations:\n300\n\n\nModel:\nLogit\nDf Residuals:\n297\n\n\nMethod:\nMLE\nDf Model:\n2\n\n\nDate:\nTue, 14 Feb 2023\nPseudo R-squ.:\n0.4474\n\n\nTime:\n12:03:29\nLog-Likelihood:\n-107.67\n\n\nconverged:\nTrue\nLL-Null:\n-194.85\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n1.385e-38\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-11.9432\n1.424\n-8.386\n0.000\n-14.735\n-9.152\n\n\nAge\n0.2242\n0.028\n7.890\n0.000\n0.168\n0.280\n\n\nEstimatedSalary\n3.48e-05\n6.15e-06\n5.660\n0.000\n2.27e-05\n4.68e-05\n\n\n\n\n\n\nconfusion_matrix_train(logit_model2)\n\nClassification accuracy = 83.3%\n\n\n\n\n\n\n\n\n\n\nconfusion_matrix_test(test,test.Purchased,logit_model2)\n\nClassification accuracy = 89.0%\n\n\n\n\n\n\n\n\n\nThe log likelihood of the model has increased, while also increasing the prediction accuracy on test data, which shows that the additional predictor is helping explain the response better, without overfitting the data.\nInclude Gender as a predictor in the above model\n\nlogit_model = sm.logit(formula = 'Purchased~Age+EstimatedSalary+Gender', data = train).fit()\nlogit_model.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.357327\n         Iterations 7\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\nPurchased\nNo. Observations:\n300\n\n\nModel:\nLogit\nDf Residuals:\n296\n\n\nMethod:\nMLE\nDf Model:\n3\n\n\nDate:\nTue, 14 Feb 2023\nPseudo R-squ.:\n0.4498\n\n\nTime:\n12:17:28\nLog-Likelihood:\n-107.20\n\n\nconverged:\nTrue\nLL-Null:\n-194.85\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n9.150e-38\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-12.2531\n1.478\n-8.293\n0.000\n-15.149\n-9.357\n\n\nGender[T.Male]\n0.3356\n0.346\n0.970\n0.332\n-0.342\n1.013\n\n\nAge\n0.2275\n0.029\n7.888\n0.000\n0.171\n0.284\n\n\nEstimatedSalary\n3.494e-05\n6.17e-06\n5.666\n0.000\n2.29e-05\n4.7e-05\n\n\n\n\n\n\nconfusion_matrix_train(logit_model)\n\nClassification accuracy = 84.3%\n\n\n\n\n\n\n\n\n\n\nconfusion_matrix_test(test,test.Purchased,logit_model)\n\nClassification accuracy = 88.0%\n\n\n\n\n\n\n\n\n\nGender is a statistically insignificant predictor, and including it slightly lowers the classification accuracy on test data. Note that the classification accuracy on training data will continue to increase on adding more predictors, irrespective of their relevance (similar to the idea of RSS on training data in linear regression).\nIs there a residual in logistic regression?\nNo, since the response is assumed to have a Bernoulli distribution, instead of a normal distribution.\nIs the odds ratio for a unit increase in a predictor \\(X_j\\), a constant (assuming that the rest of the predictors are held constant)?\nYes, the odds ratio in this case will \\(e^{\\beta_j}\\)",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#variable-transformations-in-logistic-regression",
    "href": "Lec7_logistic_regression.html#variable-transformations-in-logistic-regression",
    "title": "4  Logistic regression",
    "section": "4.5 Variable transformations in logistic regression",
    "text": "4.5 Variable transformations in logistic regression\nRead the dataset diabetes.csv that contains if a person has diabetes (Outcome = 1) based on health parameters such as BMI, blood pressure, age etc. Develop a model to predict the probability of a person having diabetes based on their age.\n\ndata = pd.read_csv('./Datasets/diabetes.csv')\n\n\ndata.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\nRandomly select 80% of the observations to create a training dataset. Create a test dataset with the remaining 20% observations.\n\n#Creating training and test datasets\nnp.random.seed(2)\ntrain = data.sample(round(data.shape[0]*0.8))\ntest = data.drop(train.index)\n\nDoes Age seem to distinguish Outcome levels?\n\nsns.boxplot(x = 'Outcome', y = 'Age', data = train)\n\n\n\n\n\n\n\n\nYes it does!\nDevelop and visualize a logistic regression model to predict Outcome using Age.\n\n#Jittering points to better see the density of points in any given region of the plot\ndef jitter(values,j):\n    return values + np.random.normal(j,0.02,values.shape)\nsns.scatterplot(x = jitter(train.Age,0), y = jitter(train.Outcome,0), data = train, color = 'orange')\nlogit_model = sm.logit(formula = 'Outcome~Age', data = train).fit()\nsns.lineplot(x = 'Age', y= logit_model.predict(train), data = train, color = 'blue') \nprint(logit_model.llf) #Printing the log likelihood to compare it with the next model we build\n\nOptimization terminated successfully.\n         Current function value: 0.612356\n         Iterations 5\n-375.9863802089716\n\n\n\n\n\n\n\n\n\n\nconfusion_matrix_train(logit_model)\n\nClassification accuracy = 65.6%\n\n\n\n\n\n\n\n\n\nClassification accuracy on train data = 66%\n\nconfusion_matrix_test(test,test.Outcome,logit_model)\n\nClassification accuracy = 59.7%\n\n\n\n\n\n\n\n\n\nClassification accuracy on test data = 60%\nCan a tranformation of Age provide a more accurate model?\nLet us visualize how the probability of people having diabetes varies with Age. We will bin Age to get the percentage of people having diabetes within different Age bins.\n\n#Binning Age\nbinned_age = pd.qcut(train['Age'],11,retbins=True)\ntrain['age_binned'] = binned_age[0]\n\n\n#Finding percentage of people having diabetes in each Age bin\nage_data = train.groupby('age_binned')['Outcome'].agg([('diabetes_percent','mean'),('nobs','count')]).reset_index(drop=False)\nage_data\n\n\n\n\n\n\n\n\nage_binned\ndiabetes_percent\nnobs\n\n\n\n\n0\n(20.999, 22.0]\n0.110092\n109\n\n\n1\n(22.0, 23.0]\n0.206897\n29\n\n\n2\n(23.0, 25.0]\n0.243243\n74\n\n\n3\n(25.0, 26.0]\n0.259259\n27\n\n\n4\n(26.0, 28.0]\n0.271186\n59\n\n\n5\n(28.0, 31.0]\n0.415094\n53\n\n\n6\n(31.0, 35.0]\n0.434783\n46\n\n\n7\n(35.0, 39.0]\n0.450980\n51\n\n\n8\n(39.0, 43.545]\n0.500000\n54\n\n\n9\n(43.545, 52.0]\n0.576271\n59\n\n\n10\n(52.0, 81.0]\n0.415094\n53\n\n\n\n\n\n\n\n\n#Visualizing percentage of people having diabetes with increasing Age (or Age bins)\nsns.lineplot(x = age_data.index, y= age_data['diabetes_percent'])\nplt.xlabel('Age_bin')\n\nText(0.5, 0, 'Age_bin')\n\n\n\n\n\n\n\n\n\nWe observe that the probability of people having diabetes does not keep increasing monotonically with age. People with ages 52 and more have a lower probability of having diabetes than people in the immediately younger Age bin.\nA quadratic transformation of Age may better fit the above trend\n\n#Model with the quadratic transformation of Age\ndef jitter(values,j):\n    return values + np.random.normal(j,0.02,values.shape)\nsns.scatterplot(x = jitter(train.Age,0), y = jitter(train.Outcome,0), data = train, color = 'orange')\nlogit_model = sm.logit(formula = 'Outcome~Age+I(Age**2)', data = train).fit()\nsns.lineplot(x = 'Age', y= logit_model.predict(train), data = train, color = 'blue') \nlogit_model.llf\n\nOptimization terminated successfully.\n         Current function value: 0.586025\n         Iterations 6\n\n\n-359.81925590230185\n\n\n\n\n\n\n\n\n\n\nlogit_model.summary()\n\n\nLogit Regression Results\n\n\nDep. Variable:\nOutcome\nNo. Observations:\n614\n\n\nModel:\nLogit\nDf Residuals:\n611\n\n\nMethod:\nMLE\nDf Model:\n2\n\n\nDate:\nTue, 14 Feb 2023\nPseudo R-squ.:\n0.08307\n\n\nTime:\n12:25:54\nLog-Likelihood:\n-359.82\n\n\nconverged:\nTrue\nLL-Null:\n-392.42\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n6.965e-15\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-6.6485\n0.908\n-7.320\n0.000\n-8.429\n-4.868\n\n\nAge\n0.2936\n0.048\n6.101\n0.000\n0.199\n0.388\n\n\nI(Age ** 2)\n-0.0031\n0.001\n-5.280\n0.000\n-0.004\n-0.002\n\n\n\n\n\nThe log likelihood of the model is higher and both the predictors are statistically significant indicating a better model fit. However, the model may also be overfitting. Let us check the model accuracy on test data.\n\nconfusion_matrix_train(logit_model)\n\nClassification accuracy = 68.1%\n\n\n\n\n\n\n\n\n\n\nconfusion_matrix_test(test,test.Outcome,logit_model)\n\nClassification accuracy = 68.8%\n\n\n\n\n\n\n\n\n\nThe classification accuracy on test data has increased to 69%. However, the number of false positives have increased. But in case of diabetes, false negatives are more concerning than false positives. This is because if a person has diabetes, and is told that they do not have diabetes, their condition may deteriorate. If a person does not have diabetes, and is told that they have diabetes, they may take unnecessary precautions or tests, but it will not be as harmful to the person as in the previous case. So, in this problem, we will be more focused on reducing the number of false negatives, instead of reducing the false positives or increasing the overall classification accuracy.\nWe can decrease the cutoff for classifying a person as having diabetes to reduce the number of false negatives.\n\n#Reducing the cutoff for classifying a person as diabetic to 0.3 (instead of 0.5)\nconfusion_matrix_test(test,test.Outcome,logit_model,0.3)\n\nClassification accuracy = 69.5%\n\n\n\n\n\n\n\n\n\nNote that the changed cut-off reduced the number of false negatives, but at the cost of increasing the false positives. However, the stakeholders may prefer the reduced cut-off to be safer.\nIs there another way to transform Age?\nYes, binning age into bins that have similar proportion of people with diabetes may provide a better model fit.\n\n#Creating a function to bin age so that it can be applied to both the test and train datasets\ndef var_transform(data):\n    binned_age = pd.qcut(train['Age'],10,retbins=True)\n    bins = binned_age[1]\n    data['age_binned'] = pd.cut(data['Age'],bins = bins)\n    dum = pd.get_dummies(data.age_binned,drop_first = True)\n    dum.columns = ['age'+str(x) for x in range(1,len(bins)-1)]\n    data = pd.concat([data,dum], axis = 1)\n    return data\n\n\n#Binning age using the function var_transform()\ntrain = var_transform(train)\ntest = var_transform(test)\n\n\n#Re-creating the plot of diabetes_percent vs age created earlier, just to check if the function binned age correctly. Yes, it did.\nage_data = train.groupby('age_binned')['Outcome'].agg([('diabetes_percent','mean'),('nobs','count')]).reset_index(drop=False)\nsns.lineplot(x = age_data.index, y= age_data['diabetes_percent'])\nplt.xlabel('Age_bin')\n\nText(0.5, 0, 'Age_bin')\n\n\n\n\n\n\n\n\n\n\n#Model with binned Age\ndef jitter(values,j):\n    return values + np.random.normal(j,0.02,values.shape)\nsns.scatterplot(x = jitter(train.Age,0), y = jitter(train.Outcome,0), data = train, color = 'orange')\nlogit_model = sm.logit(formula = 'Outcome~' + '+'.join(['age'+str(x) for x in range(1,10)]), data = train).fit()\nsns.lineplot(x = 'Age', y= logit_model.predict(train), data = train, color = 'blue') \n\nOptimization terminated successfully.\n         Current function value: 0.585956\n         Iterations 6\n\n\n\n\n\n\n\n\n\n\nlogit_model.summary()\n\n\nLogit Regression Results\n\n\nDep. Variable:\nOutcome\nNo. Observations:\n614\n\n\nModel:\nLogit\nDf Residuals:\n604\n\n\nMethod:\nMLE\nDf Model:\n9\n\n\nDate:\nSun, 19 Feb 2023\nPseudo R-squ.:\n0.08318\n\n\nTime:\n14:19:51\nLog-Likelihood:\n-359.78\n\n\nconverged:\nTrue\nLL-Null:\n-392.42\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n1.273e-10\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.0898\n0.306\n-6.829\n0.000\n-2.690\n-1.490\n\n\nage1\n0.7461\n0.551\n1.354\n0.176\n-0.334\n1.826\n\n\nage2\n0.9548\n0.409\n2.336\n0.019\n0.154\n1.756\n\n\nage3\n1.0602\n0.429\n2.471\n0.013\n0.219\n1.901\n\n\nage4\n1.3321\n0.438\n3.044\n0.002\n0.474\n2.190\n\n\nage5\n1.9606\n0.398\n4.926\n0.000\n1.180\n2.741\n\n\nage6\n1.8303\n0.399\n4.586\n0.000\n1.048\n2.612\n\n\nage7\n1.7596\n0.410\n4.288\n0.000\n0.955\n2.564\n\n\nage8\n2.4544\n0.402\n6.109\n0.000\n1.667\n3.242\n\n\nage9\n1.8822\n0.404\n4.657\n0.000\n1.090\n2.674\n\n\n\n\n\nNote that the probability of having diabetes for each age bin is a constant, as per the above plot.\n\nconfusion_matrix_test(test,test.Outcome,logit_model,0.3)\n\nClassification accuracy = 67.5%\n\n\n\n\n\n\n\n\n\nBinning Age provides a similar result as compared to the model with the quadratic transformation of Age.\n\ntrain.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\nage_binned\nage1\nage2\nage3\nage4\nage5\nage6\nage7\nage8\nage9\n\n\n\n\n158\n2\n88\n74\n19\n53\n29.0\n0.229\n22\n0\n(21.0, 22.0]\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n251\n2\n129\n84\n0\n0\n28.0\n0.284\n27\n0\n(25.0, 27.0]\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n631\n0\n102\n78\n40\n90\n34.5\n0.238\n24\n0\n(23.0, 25.0]\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n757\n0\n123\n72\n0\n0\n36.3\n0.258\n52\n1\n(51.0, 81.0]\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n689\n1\n144\n82\n46\n180\n46.1\n0.335\n46\n1\n(42.0, 51.0]\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n\n\n\n\n\n\n#Model with the quadratic transformation of Age and more predictors\nlogit_model_diabetes = sm.logit(formula = 'Outcome~Age+I(Age**2)+Glucose+BloodPressure+BMI+DiabetesPedigreeFunction', data = train).fit()\nlogit_model_diabetes.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.470478\n         Iterations 6\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\nOutcome\nNo. Observations:\n614\n\n\nModel:\nLogit\nDf Residuals:\n607\n\n\nMethod:\nMLE\nDf Model:\n6\n\n\nDate:\nThu, 23 Feb 2023\nPseudo R-squ.:\n0.2639\n\n\nTime:\n10:26:00\nLog-Likelihood:\n-288.87\n\n\nconverged:\nTrue\nLL-Null:\n-392.42\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n5.878e-42\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-12.3347\n1.282\n-9.621\n0.000\n-14.847\n-9.822\n\n\nAge\n0.2852\n0.056\n5.121\n0.000\n0.176\n0.394\n\n\nI(Age ** 2)\n-0.0030\n0.001\n-4.453\n0.000\n-0.004\n-0.002\n\n\nGlucose\n0.0309\n0.004\n8.199\n0.000\n0.024\n0.038\n\n\nBloodPressure\n-0.0141\n0.006\n-2.426\n0.015\n-0.025\n-0.003\n\n\nBMI\n0.0800\n0.016\n4.978\n0.000\n0.049\n0.112\n\n\nDiabetesPedigreeFunction\n0.7138\n0.322\n2.213\n0.027\n0.082\n1.346\n\n\n\n\n\nAdding more predictors has increased the log likelihood of the model as expected.\n\nconfusion_matrix_train(logit_model_diabetes,cutoff=0.3)\n\nClassification accuracy = 74.3%\n\n\n\n\n\n\n\n\n\n\nconfusion_matrix_test(test,test.Outcome,logit_model_diabetes,0.3)\n\nClassification accuracy = 80.5%\n\n\n\n\n\n\n\n\n\nThe model with more predictors also has lesser number of false negatives, and higher overall classification accuracy.\nHow many bins must you make for Age to get the most accurate model?\nIf the number of bins are too less, the trend may not be captured accurately. If the number of bins are too many, it may lead to overfitting of the model. There is an optimal value of the number of bins that captures the trend, but does not overfit. A couple of ways of estimating the optimal number of bins can be:\n\nThe number of bins for which the trend continues to be “almost” the same for several samples of the data.\nTesting the model on multiple test datasets.\n\nOptimizing the number of bins for each predictor may be a time-consuming exercises. You may do it for your course project. However, we will not do it here in the class notes.",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Lec7_logistic_regression.html#performance-measurement",
    "href": "Lec7_logistic_regression.html#performance-measurement",
    "title": "4  Logistic regression",
    "section": "4.6 Performance Measurement",
    "text": "4.6 Performance Measurement\nWe have already seen the confusion matrix, and classification accuracy. Now, let us see some other useful performance metrics that can be computed from the confusion matrix. The metrics below are computed for the confusion matrix immediately above this section (or the confusion matrix on test data corresponding to the model logit_model_diabetes).\n\n4.6.1 Precision-recall\nPrecision measures the accuracy of positive predictions. Also called the precision of the classifier\n\\[\\textrm{precision} = \\frac{\\textrm{True Positives}}{\\textrm{True Positives} + \\textrm{False Positives}}\\]\n==&gt; 70.13%\nPrecision is typically used with recall (Sensitivity or True Positive Rate). The ratio of positive instances that are correctly detected by the classifier.\n\\[\\textrm{recall} = \\frac{\\textrm{True Positives}}{\\textrm{True Positives} + \\textrm{False Negatives}}\\] ==&gt; 88.52%\nPrecision / Recall Tradeoff: Increasing precision reduces recall and vice versa.\nVisualize the precision-recall curve for the model logit_model_diabetes.\n\nfrom sklearn.metrics import precision_recall_curve\ny=train.Outcome\nypred = logit_model_diabetes.predict(train)\np, r, thresholds = precision_recall_curve(y, ypred)\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.figure(figsize=(8, 8))\n    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.ylabel(\"Score\")\n    plt.xlabel(\"Decision Threshold\")\n    plt.legend(loc='best')\n    plt.legend()\nplot_precision_recall_vs_threshold(p, r, thresholds)\n\n\n\n\n\n\n\n\nAs the decision threshold probability increases, the precision increases, while the recall decreases.\nQ: How are the values of the thresholds chosen to make the precision-recall curve?\nHint: Look at the documentation for precision_recall_curve.\n\n\n4.6.2 The Receiver Operating Characteristics (ROC) Curve\nA ROC(Receiver Operator Characteristic Curve) is a plot of sensitivity (True Positive Rate) on the y axis against (1−specificity) (False Positive Rate) on the x axis for varying values of the threshold t. The 45° diagonal line connecting (0,0) to (1,1) is the ROC curve corresponding to random chance. The ROC curve for the gold standard is the line connecting (0,0) to (0,1) and (0,1) to (1,1).\n\n\n\n\n\n\n\n\n\n\nAn animation to demonstrate how an ROC curve relates to sensitivity and specificity for all possible cutoffs (Source)\nHigh Threshold:\n\nHigh specificity\nLow sensitivity\n\nLow Threshold\n\nLow specificity\nHigh sensitivity\n\nThe area under ROC is called Area Under the Curve(AUC). AUC gives the rate of successful classification by the logistic model. To get a more in-depth idea of what a ROC-AUC curve is and how is it calculated, here is a good blog link.\nHere is good post by google developers on interpreting ROC-AUC, and its advantages / disadvantages.\nVisualize the ROC curve and compute the ROC-AUC for the model logit_model_diabetes.\n\nfrom sklearn.metrics import roc_curve, auc\ny=train.Outcome\nypred = logit_model_diabetes.predict(train)\nfpr, tpr, auc_thresholds = roc_curve(y, ypred)\nprint(auc(fpr, tpr))# AUC of ROC\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.figure(figsize=(8,8))\n    plt.title('ROC Curve')\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.005, 1, 0, 1.005])\n    plt.xticks(np.arange(0,1, 0.05), rotation=90)\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate (Recall)\")\n\nfpr, tpr, auc_thresholds = roc_curve(y, ypred)\nplot_roc_curve(fpr, tpr)\n\n0.8325914847653979\n\n\n\n\n\n\n\n\n\nQ: How are the values of the auc_thresholds chosen to make the ROC curve? Why does it look like a step function?\nBelow is a function that prints the confusion matrix along with all the performance metrics we discussed above for a given decision threshold probability, on train / test data. Note that ROC-AUC does not depend on a decision threshold probability.\n\n#Function to compute confusion matrix and prediction accuracy on test/train data\ndef confusion_matrix_data(data,actual_values,model,cutoff=0.5):\n#Predict the values using the Logit model\n    pred_values = model.predict(data)\n# Specify the bins\n    bins=np.array([0,cutoff,1])\n#Confusion matrix\n    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n    cm_df = pd.DataFrame(cm)\n    cm_df.columns = ['Predicted 0','Predicted 1']\n    cm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n# Calculate the accuracy\n    accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n    fnr = (cm[1,0])/(cm[1,0]+cm[1,1])\n    precision = (cm[1,1])/(cm[0,1]+cm[1,1])\n    fpr = (cm[0,1])/(cm[0,0]+cm[0,1])\n    tpr = (cm[1,1])/(cm[1,0]+cm[1,1])\n    fpr_roc, tpr_roc, auc_thresholds = roc_curve(actual_values, pred_values)\n    auc_value = (auc(fpr_roc, tpr_roc))# AUC of ROC\n    sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n    plt.ylabel(\"Actual Values\")\n    plt.xlabel(\"Predicted Values\")\n    print(\"Classification accuracy = {:.1%}\".format(accuracy))\n    print(\"Precision = {:.1%}\".format(precision))\n    print(\"TPR or Recall = {:.1%}\".format(tpr))\n    print(\"FNR = {:.1%}\".format(fnr))\n    print(\"FPR = {:.1%}\".format(fpr))\n    print(\"ROC-AUC = {:.1%}\".format(auc_value))\n\n\nconfusion_matrix_data(test,test.Outcome,logit_model_diabetes,0.3)\n\nClassification accuracy = 80.5%\nPrecision = 70.1%\nTPR or Recall = 88.5%\nFNR = 11.5%\nFPR = 24.7%\nROC-AUC = 90.1%",
    "crumbs": [
      "Linear regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html",
    "href": "Assignment 1 (Section 20).html",
    "title": "Assignment 1 (Section 20)",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#instructions",
    "href": "Assignment 1 (Section 20).html#instructions",
    "title": "Assignment 1 (Section 20)",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nDo not write your name on the assignment.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Wednesday, 24th January 2024 at 11:59 pm.\nThere is a bonus question worth 15 points.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 100 + 15 (bonus question) + 5 (proper formatting) = 120 out of 100. There is no partial credit for some parts of the bonus question.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "href": "Assignment 1 (Section 20).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "title": "Assignment 1 (Section 20)",
    "section": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)",
    "text": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)\n\n1a)\nFor each case below, explain (1) whether it is a classification or a regression problem and (2) whether the main purpose is prediction or inference. You need justify your answers for credit.\n\n\n1b)\nYou work for a company that is interested in conducting a marketing campaign. The goal of your project is to identify individuals who are likely to respond positively to a marketing campaign, based on observations of demographic variables (such as age, gender, income etc.) measured on each individual. (2+2 points)\n\n\n1c)\nFor the same company, now you are working on a different project. This one is focused on understanding the impact of advertisements in different media types on the company sales. For example, you are interested in the following question: ‘How large of an increase in sales is associated with a given increase in radio and TV advertising?’ (2+2 points)\n\n\n1d)\nA company is selling furniture and they are interested in the finding the association between demographic characteristics of customers (such as age, gender, income etc.) and if they would purchase a particular company product. (2+2 points)\n\n\n1e)\nWe are interested in forecasting the % change in the USD/Euro exchange rate using the weekly changes in the stock markets of a number of countries. We collect weekly data for all of 2023. For each week, we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market. (2+2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "href": "Assignment 1 (Section 20).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "title": "Assignment 1 (Section 20)",
    "section": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)",
    "text": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)\n\n2a)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the root mean squared error (RMSE) metric as compared to the mean absolute error (MAE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.\n\n\n2b)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the mean absolute error (MAE) metric as compared to the root mean squared error (RMSE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#modeling-the-petrol-consumption-in-u.s.-states-61-points",
    "href": "Assignment 1 (Section 20).html#modeling-the-petrol-consumption-in-u.s.-states-61-points",
    "title": "Assignment 1 (Section 20)",
    "section": "3) Modeling the Petrol Consumption in U.S. States (61 points)",
    "text": "3) Modeling the Petrol Consumption in U.S. States (61 points)\nRead petrol_consumption_train.csv. Assume that each observation is a U.S. state. For each observation, the data has the following variables as its five columns:\nPetrol_tax: Petrol tax (cents per gallon)\nPer_capita_income: Average income (dollars)\nPaved_highways: Paved Highways (miles)\nProp_license: Proportion of population with driver’s licenses\nPetrol_consumption: Consumption of petrol (millions of gallons)\n\n3a)\nCreate a pairwise plot of all the variables in the dataset. (1 point) Print the correlation matrix of all the variables as well. (1 point) Which variable has the highest linear correlation with Petrol_consumption? (2 points)\nNote: Remember that a pairwise plot is a visualization tool that you can find in the seaborn library.\n\n\n3b)\nFit a simple linear regression model to predict Petrol_consumption using the column you found in part a as the only predictor. Print the model summary. (4 points)\n\n\n3c)\nWhat is the increase in petrol consumption for an increase of 0.05 in the predictor? (4 points)\n\n\n3d)\nDoes petrol consumption have a statistically significant relationship with the predictor? You need to justify your answer for credit. (4 points)\n\n\n3e)\nHow much of the variation in petrol consumption can be explained by its linear relationship with the predictor? (3 points)\n\n\n3f)\nPredict the petrol consumption for a state in which 50% of the population has a driver’s license. (3 points) What are the confidence interval (3 points) and the prediction interval (3 points) for your prediction? Which interval is wider? (1 points) Why? (2 points)\n\n\n3g)\nPredict the petrol consumption for a state in which 10% of the population has a driver’s license. (3 points) Are you getting a reasonable outcome? (1 point) Why or why not? (2 points)\n\n\n3h)\nWhat is the residual standard error of the model? (3 points)\n\n\n3i)\nUsing the trained model, predict the petrol consumption of the observations in petrol_consumption_test.csv (2 points) and find the RMSE. (2 points) What is the unit of this RMSE value? (1 point)\n\n\n3j)\nBased on the answers to part g and part h, do you think the model is overfitting? You need to justify your answer for credit. (4 points)\n\n\n3k)\nMake a scatterplot of Petrol_consumption vs. the predictor using petrol_consumption_test.csv. (1 point) Over the scatterplot, plot the regression line (2 points), the prediction interval (2 points), and the confidence interval. (2 points)\nMake sure that regression line, prediction interval lines, and confidence interval lines have different colors. (1 point) Display a legend that correctly labels the lines as well. (1 point) Note that you need two lines of the same color to plot an interval.\n\n\n3l)\nFind the correlation between Petrol_consumption and the rest of the variables in petrol_consumption_train.csv. Which column would have the lowest R-squared value when used as the predictor for a Simple Linear Regression model to predict Petrol_consumption? Note that you can directly answer this question from the correlation values and do not need to develop any more linear regression models. (3 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#reproducing-the-results-with-scikit-learn-15-points",
    "href": "Assignment 1 (Section 20).html#reproducing-the-results-with-scikit-learn-15-points",
    "title": "Assignment 1 (Section 20)",
    "section": "4) Reproducing the Results with Scikit-Learn (15 points)",
    "text": "4) Reproducing the Results with Scikit-Learn (15 points)\n\n4a)\nUsing the same datasets, same response and the same predictor as Question 3, reproduce the following outputs with scikit-learn:\n\nModel RMSE for test data (3 points)\nR-squared value of the model (3 points)\nResidual standard error of the model (3 points)\n\nNote that you are only allowed to use scikit-learn, pandas, and numpy tools for this question. Any other libraries will not receive any credit.\n\n\n4b)\nWhich of the model outputs from Question 3 cannot be reproduced using scikit-learn? Give two answers. (2+2 points) What does this tell about scikit-learn? (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Section 20).html#bonus-question-15-points",
    "href": "Assignment 1 (Section 20).html#bonus-question-15-points",
    "title": "Assignment 1 (Section 20)",
    "section": "5) Bonus Question (15 points)",
    "text": "5) Bonus Question (15 points)\nPlease note that the bonus question requires you to look more into the usage of the tools we covered in class and it will be necessary to do your own research. We strongly suggest attempting it after you are done with the rest of the assignment.\n\n5a)\nFit a simple linear regression model to predict Petrol_consumption based on the predictor in Question 3, but without an intercept term. (5 points - no partial credit)\nWithout an intercept means that the equation becomes \\(Y = \\beta_1X\\). The intercept term, \\(\\beta_0\\), becomes 0.\nNote: You must answer this part correctly to qualify for the bonus points in the following parts.\n\n\n5b)\nPredict the petrol consumption for the observations in petrol_consumption_test.csv using the model without an intercept and find the RMSE. (1+2 points) Then, print the summary and find the R-squared. (2 points)\n\n\n5c)\nThe RMSE for the models with and without the intercept are similar, which indicates that both models are almost equally good. However, the R-squared for the model without intercept is much higher than the R-squared for the model with the intercept. Why? Justify your answer. (5 points - no partial credit)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 1 (Section 20)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html",
    "href": "Assignment 1 (Sections 21 & 22).html",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#instructions",
    "href": "Assignment 1 (Sections 21 & 22).html#instructions",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nDo not write your name on the assignment.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Wednesday, 24th January 2024 at 11:59 pm.\nThere is a bonus question worth 15 points.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 100 + 15 (bonus question) + 5 (proper formatting) = 120 out of 100. There is no partial credit for some parts of the bonus question.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "href": "Assignment 1 (Sections 21 & 22).html#case-studies-regression-vs-classification-and-prediction-vs-inference-16-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)",
    "text": "1) Case Studies: Regression vs Classification and Prediction vs Inference (16 points)\nFor each case below, explain (1) whether it is a classification or a regression problem and (2) whether the main purpose is prediction or inference. You need justify your answers for credit.\n\n1a)\nYou work for a company that is interested in conducting a marketing campaign. The goal of your project is to identify individuals who are likely to respond positively to a marketing campaign, based on observations of demographic variables (such as age, gender, income etc.) measured on each individual. (2+2 points)\n\n\n1b)\nFor the same company, now you are working on a different project. This one is focused on understanding the impact of advertisements in different media types on the company sales. For example, you are interested in the following question: ‘How large of an increase in sales is associated with a given increase in radio and TV advertising?’ (2+2 points)\n\n\n1c)\nA company is selling furniture and they are interested in the finding the association between demographic characteristics of customers (such as age, gender, income etc.) and if they would purchase a particular company product. (2+2 points)\n\n\n1d)\nWe are interested in forecasting the % change in the USD/Euro exchange rate using the weekly changes in the stock markets of a number of countries. We collect weekly data for all of 2023. For each week, we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market. (2+2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "href": "Assignment 1 (Sections 21 & 22).html#examples-for-different-regression-metrics-rmse-vs-mae-8-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)",
    "text": "2) Examples for Different Regression Metrics: RMSE vs MAE (8 points)\n\n2a)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the root mean squared error (RMSE) metric as compared to the mean absolute error (MAE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.\n\n\n2b)\nDescribe a regression problem, where it will be more proper to evaluate the model performance using the mean absolute error (MAE) metric as compared to the root mean squared error (RMSE) metric. You need to justify your answer for credit. (4 points)\nNote: You are not allowed to use the datasets and examples covered in the lectures.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#simple-linear-regression-formulation-3-points",
    "href": "Assignment 1 (Sections 21 & 22).html#simple-linear-regression-formulation-3-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "3) Simple Linear Regression: Formulation (3 points)",
    "text": "3) Simple Linear Regression: Formulation (3 points)\nWhen asked to state the simple linear regression model, a students wrote it as follows: \\(E(Y_i) = \\beta_0 + \\beta_1X_i + \\epsilon_i\\). Is this correct (1 point)? Justify your answer (2 points).",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#modeling-the-petrol-consumption-in-u.s.-states-58-points",
    "href": "Assignment 1 (Sections 21 & 22).html#modeling-the-petrol-consumption-in-u.s.-states-58-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "4) Modeling the Petrol Consumption in U.S. States (58 points)",
    "text": "4) Modeling the Petrol Consumption in U.S. States (58 points)\nRead petrol_consumption_train.csv. Assume that each observation is a U.S. state. For each observation, the data has the following variables as its five columns:\nPetrol_tax: Petrol tax (cents per gallon)\nPer_capita_income: Average income (dollars)\nPaved_highways: Paved Highways (miles)\nProp_license: Proportion of population with driver’s licenses\nPetrol_consumption: Consumption of petrol (millions of gallons)\n\n4a)\nCreate a pairwise plot of all the variables in the dataset. (1 point) Print the correlation matrix of all the variables as well. (1 point) Which variable has the highest linear correlation with Petrol_consumption? (1 point)\nNote: Remember that a pairwise plot is a visualization tool that you can find in the seaborn library.\n\n\n4b)\nFit a simple linear regression model to predict Petrol_consumption using the column you found in part a as the only predictor. Print the model summary. (3 points)\n\n\n4c)\nWhen asked for a point estimate of the expected petrol consumption for a state where the proportion of population with driver’s license is 54.4%, a person gave the estimate 488 million gallons because that is the mean value of Petrol_consumption for the two observations of Prop_license = 0.544 pieces in the dataset. Is there an issue with this approach? Explain. (2 points) If there is an issue, then suggest a better approach and use it to estimate the expected petrol consumption for a state where the proportion of population with driver’s license is 54.4%. (2 points)\n\n\n4d)\nWhat is the increase in petrol consumption for an increase of 0.05 in the predictor? (3 points)\n\n\n4e)\nDoes petrol consumption have a statistically significant relationship with the predictor? You need to justify your answer for credit. (3 points)\n\n\n4f)\nHow much of the variation in petrol consumption can be explained by its linear relationship with the predictor? (2 points)\n\n\n4g)\nPredict the petrol consumption for a state in which 50% of the population has a driver’s license. (2 points) What are the confidence interval (2 points) and the prediction interval (2 points) for your prediction? Which interval is wider? (1 points) Why? (2 points)\n\n\n4h)\nPredict the petrol consumption for a state in which 10% of the population has a driver’s license. (3 points) Are you getting a reasonable outcome? (1 point) Why or why not? (2 points)\n\n\n4i)\nWhat is the residual standard error of the model? (3 points)\n\n\n4j)\nUsing the trained model, predict the petrol consumption of the observations in petrol_consumption_test.csv (2 points) and find the RMSE. (2 points) What is the unit of this RMSE value? (1 point)\n\n\n4k)\nBased on the answers to part i and part j, do you think the model is overfitting? You need to justify your answer for credit. (3 points)\n\n\n4l)\nMake a scatterplot of Petrol_consumption vs. the predictor using petrol_consumption_test.csv. (1 point) Over the scatterplot, plot the regression line (1 point), the prediction interval (2 points), and the confidence interval. (2 points)\nMake sure that regression line, prediction interval lines, and confidence interval lines have different colors. (1 point) Display a legend that correctly labels the lines as well. (1 point) Note that you need two lines of the same color to plot an interval.\n\n\n4m)\nThe dataset consists of 40 US States. If you combine this data with the data of the remaining 10 US States, are you likely to obtain narrower confidence and prediction intervals in the plot developed in the previous question, for the same level of confidence? Justify your answer. (2 points).\nIf yes, then can you gaurantee that the width of these intervals will reduce? Justify your answer. If no, then can you gaurantee that the width of these intervals will not reduce? Justify your answer. (2 points)\n\n\n4n)\nFind the correlation between Petrol_consumption and the rest of the variables in petrol_consumption_train.csv. Which column would have the lowest R-squared value when used as the predictor for a Simple Linear Regression model to predict Petrol_consumption? Note that you can directly answer this question from the correlation values and do not need to develop any more linear regression models. (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#reproducing-the-results-with-scikit-learn-15-points",
    "href": "Assignment 1 (Sections 21 & 22).html#reproducing-the-results-with-scikit-learn-15-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "5) Reproducing the Results with Scikit-Learn (15 points)",
    "text": "5) Reproducing the Results with Scikit-Learn (15 points)\n\n5a)\nUsing the same datasets, same response and the same predictor as Question 4, reproduce the following outputs with scikit-learn:\n\nModel RMSE for test data (3 points)\nR-squared value of the model (3 points)\nResidual standard error of the model (3 points)\n\nNote that you are only allowed to use scikit-learn, pandas, and numpy tools for this question. Any other libraries will not receive any credit.\n\n\n5b)\nWhich of the model outputs from Question 4 cannot be reproduced using scikit-learn? Give two answers. (2+2 points) What does this tell about scikit-learn? (2 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 1 (Sections 21 & 22).html#bonus-question-15-points",
    "href": "Assignment 1 (Sections 21 & 22).html#bonus-question-15-points",
    "title": "Assignment 1 (Sections 21 & 22)",
    "section": "6) Bonus Question (15 points)",
    "text": "6) Bonus Question (15 points)\nPlease note that the bonus question requires you to look more into the usage of the tools we covered in class and it will be necessary to do your own research. We strongly suggest attempting it after you are done with the rest of the assignment.\n\n6a)\nFit a simple linear regression model to predict Petrol_consumption based on the predictor in Question 4, but without an intercept term. (5 points - no partial credit)\nWithout an intercept means that the equation becomes \\(Y = \\beta_1X\\). The intercept term, \\(\\beta_0\\), becomes 0.\nNote: You must answer this part correctly to qualify for the bonus points in the following parts.\n\n\n6b)\nPredict the petrol consumption for the observations in petrol_consumption_test.csv using the model without an intercept and find the RMSE. (1+2 points) Then, print the summary and find the R-squared. (2 points)\n\n\n6c)\nThe RMSE for the models with and without the intercept are similar, which indicates that both models are almost equally good. However, the R-squared for the model without intercept is much higher than the R-squared for the model with the intercept. Why? Justify your answer. (5 points - no partial credit)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Assignment 1 (Sections 21 & 22)</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html",
    "href": "Assignment 2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#instructions",
    "href": "Assignment 2.html#instructions",
    "title": "Assignment 2",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nWrite your code in the Code cells and your answers in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to for the graders to understand and follow.\nUse Quarto to render the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on Sunday, 4th February 2024 at 11:59 pm.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\nMust be an HTML file rendered using Quarto (1 point). If you have a Quarto issue, you must mention the issue & quote the error you get when rendering using Quarto in the comments section of Canvas, and submit the ipynb file.\nNo name can be written on the assignment, nor can there be any indicator of the student’s identity—e.g. printouts of the working directory should not be included in the final submission. (1 point)\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 point)\nFinal answers to each question are written in the Markdown cells. (1 point)\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text. (1 point)\n\nThe maximum possible score in the assigment is 105 + 5 (proper formatting) = 110 out of 100.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#multiple-linear-regression-24-points",
    "href": "Assignment 2.html#multiple-linear-regression-24-points",
    "title": "Assignment 2",
    "section": "1) Multiple Linear Regression (24 points)",
    "text": "1) Multiple Linear Regression (24 points)\nA study was conducted on 97 male patients with prostate cancer who were due to receive a radical prostatectomy (complete removal of the prostate). The prostate.csv file contains data on 9 measurements taken from these 97 patients. Each row (observation) represents a patient and each column (variable) represents a measurement. The description of variables can be found here: https://rafalab.github.io/pages/649/prostate.html\n\n1a)\nFit a linear regression model with lpsa as the response and all the other variables as the predictors. Print its summary. (2 points) Write down the optimal equation that predicts lpsa using the predictors. (2 points)\n\n\n1b)\nIs the overall regression statistically significant? In other words, is there a statistically significant relationship between the response and at least one predictor? You need to justify your answer for credit. (2 points)\n\n\n1c)\nWhat does the optimal coefficient of svi tell us as a numeric output? Make sure you include the predictor, (svi) the response (lpsa) and the other predictors in your answer. (2 points)\n\n\n1d)\nCheck the \\(p\\)-values of gleason and age. Are these predictors statistically significant? You need to justify your answer for credit. (2 points)\n\n\n1e)\nCheck the 95% Confidence Interval of age. How can you relate it to its p-value and statistical significance, which you found in the previous part? (2 points)\n\n\n1f)\nThis question requires some thinking, and bringing your 303-1 and 303-2 knowledge together.\nFit a simple linear regression model on lpsa against gleason and check the \\(p\\)-value of gleason using the summary. (2 point) Did the statistical significance of gleason change in the absence of other predictors? (1 point) Why or why not? (3 points)\nHints:\n\nYou need to compare this model with the Multiple Linear Regression model you created above.\nPrinting a correlation matrix of all the predictors should be useful.\n\n\n\n1g)\nPredict the lpsa of a 65 year old man with lcavol = 1.35, lweight = 3.65, lbph = 0.1, svi = 0.22, lcp = -0.18, gleason = 6.75, and pgg45 = 25. Find the 95% confidence and prediction intervals as well. (2 points)\n\n\n1h)\nIn the Multiple Linear Regression model with all the predictors, you should see a total of five predictors that appear to be statistically insignificant. Why is it not a good idea to directly conclude that all of them are statistically insignificant? (2 points) Implement the additional test that concludes the statistical insignificance of all five predictors. (2 points)\nHint: f_test() method",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#multiple-linear-regression-with-variable-transformations-22-points",
    "href": "Assignment 2.html#multiple-linear-regression-with-variable-transformations-22-points",
    "title": "Assignment 2",
    "section": "2) Multiple Linear Regression with Variable Transformations (22 points)",
    "text": "2) Multiple Linear Regression with Variable Transformations (22 points)\nThe infmort.csv file has the infant mortality data of different countries in the world. The mortality column represents the infant mortality rate with “deaths per 1000 infants” as the unit. The income column represents the per capita income in USD. The other columns should be self-explanatory. (This is an old dataset, as can be seen from some country names.)\n\n2a)\nStart your analysis by creating (i) a boxplot of log(mortality) for each region and (ii) a boxplot of income for each region. Note that the region column has the continent names. (3 points)\nNote: You need to use np.log, which is the natural log. This is to better distinguish the mortality values.\n\n\n2b)\nIn the previous part, you should see that Europe has the lowest infant mortality rate on average, but it also has the highest per capita income on average. Our goal is to see if Europe still has the lowest mortality rate if we remove the effect of income. We will try to find an answer for the rest of this question.\nCreate four scatter plots: (i) mortality against income, (ii) log(mortality) against income, (iii) mortality against log(income), and (iv) log(mortality) against log(income). (3 points) Based on the plots, create an appropriate model to predict the mortality rate as a function of per capita income. Print the model summary. (2 points)\n\n\n2c)\nUpdate the model you created in the previous part by adding region as a predictor. Print the model summary. (2 points)\n\n\n2d)\nUse the model developed in the previous part to compute a new adjusted_mortality variable for each observation in the data. (5 points) Adjusted mortality rate is the mortality rate after removing the estimated effect of income. You need to calculate it with the following steps:\n\nMultiply the (transformed) income column with its optimal coefficient. This is the estimated effect of income.\nSubtract the product from the (transformed) response column. This removes the estimated effect of income.\nYou may need to do a inverse transformation to calculate the actual adjusted mortality rate values.\n\nMake a boxplot of log(adjusted_mortality) for each region. (2 points)\n\n\n2e)\nUsing the plots in parts a and d, answer the following questions:\n\nDoes Europe still have the lowest mortality rate on average after removing the effect of income?\nHow did the distribution of values among different continents change after removing the effect of income? How did the comparison of different continents change? Does any non-European country have a lower mortality rate than all the European countries after removing the effect of income?\n\n(5 points)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#variable-transformations-and-interactions-38-points",
    "href": "Assignment 2.html#variable-transformations-and-interactions-38-points",
    "title": "Assignment 2",
    "section": "3) Variable Transformations and Interactions (38 points)",
    "text": "3) Variable Transformations and Interactions (38 points)\nThe soc_ind.csv dataset contains many social indicators of a number of countries. Each row is a country and each column is a social indicator. The column names should be clear on what the variables represent. The GDP per capita will be the response variable throughout this question.\n\n3a)\nUsing correlations, find out the most useful predictor for a simple linear regression model with gdpPerCapita as the response. You can ignore categorical variables for now. Let that predictor be \\(P\\). (2 points)\n\n\n3b)\nCreate a scatterplot of gdpPerCapita vs \\(P\\). Does the relationship between gdpPerCapita and \\(P\\) seem linear or non-linear? (2 points)\n\n\n3c)\nIf the relationship in the previous part is non-linear, create three models:\n\nOnly with \\(P\\)\nWith \\(P\\) and its quadratic term\nWith \\(P\\), its quadratic term and its cubic term\n\n(2x3 = 6 points)\nCompare the \\(R\\)-squared values of the models. (2 points)\n\n\n3d)\nOn the same figure:\n\ncreate the scatterplot in part b.\nplot the linear regression line (only using \\(P\\))\nplot the polynomial regression curve that includes the quadratic and cubic terms.\nadd a legend to distinguish the linear and cubic fits.\n\n(6 points)\n\n\n3e)\nDevelop a model to predict gdpPerCapita using \\(P\\) and continent as predictors. (No higher-order terms.)\n\nWhich continent creates the baseline? (2 points) Write down its equation. (2 points)\nFor a given value of \\(P\\), are there any continents that do not have a statistically significant difference of predicted gdpPerCapita from the baseline continent? If yes, then which ones, and why? If no, then why not? You need to justify your answers for credit. (4 points)\n\n\n\n3f)\nThe model developed in the previous part has a limitation. It assumes that the increase in predicted gdpPerCapita with a unit increase in \\(P\\) does not depend on the continent.\nEliminate this limitation by including the interaction of continent with \\(P\\) in the model. Print the model summary of the model with interactions. (2 points) Which continent has the closest increase in predicted gdpPerCapita to the baseline continent with a unit increase in \\(P\\). Which continent has the furthest? You need to justify your answers for credit. (5 points)\n\n\n3g)\nUsing the model developed in the previous part, plot the regression lines of all the continents on the same figure. Put gdpPerCapita on the y-axis and \\(P\\) on the x-axis. (4 points) Use a legend to color-code the continents. (1 point)",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 2.html#prediction-with-sklearn-21-points",
    "href": "Assignment 2.html#prediction-with-sklearn-21-points",
    "title": "Assignment 2",
    "section": "4) Prediction with Sklearn (21 points)",
    "text": "4) Prediction with Sklearn (21 points)\nUsing the soc_ind.csv dataset and only sklearn and pandas, train a Linear Regression model. You need the following steps:\n\ngdpPerCapita is the response. (2 points)\nIndex, geographic_location and country columns are not necessary. (2 points)\nAll the remaining columns are predictors. (2 points)\ncontinent column needs to be one-hot-encoded. (2 points)\nSince the numeric values have different orders of magnitude, you need to scale the dataset. You can use StandardScaler from sklearn.preprocessing for this. Create an object (just like a model) and use .fit_transform with the data as the input. (4 points)\nTrain a LinearRegression model. Use the entire dataset as the training data. (3 points)\nGet the predictions for the training data. (3 points)\nCalculate the RMSE and MAE. (3 points)\n\nFor this question, you only need to calculate the training performance. In the future, we will see how to split a dataset into training and test sets.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Datasets.html",
    "href": "Datasets.html",
    "title": "Appendix A — Datasets, assignment and project files",
    "section": "",
    "text": "Datasets used in the book, assignment files, project files, and prediction problems report tempate can be found here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Datasets, assignment and project files</span>"
    ]
  }
]