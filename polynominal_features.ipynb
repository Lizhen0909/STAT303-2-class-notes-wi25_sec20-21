{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Extending Linear Regression (PolynomialFeatures in Sklearn)\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc-depth: 4\n",
    "    jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.254599</td>\n",
       "      <td>-1.063645</td>\n",
       "      <td>0.295770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.507143</td>\n",
       "      <td>-0.265643</td>\n",
       "      <td>30.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.319939</td>\n",
       "      <td>3.545474</td>\n",
       "      <td>34.523622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986585</td>\n",
       "      <td>-1.599956</td>\n",
       "      <td>-1.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.439814</td>\n",
       "      <td>3.696497</td>\n",
       "      <td>49.341010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.440055</td>\n",
       "      <td>-4.118656</td>\n",
       "      <td>-14.395442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.419164</td>\n",
       "      <td>2.767984</td>\n",
       "      <td>43.154083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.661761</td>\n",
       "      <td>3.475476</td>\n",
       "      <td>43.267654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.011150</td>\n",
       "      <td>-3.181823</td>\n",
       "      <td>-9.254211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.080726</td>\n",
       "      <td>-0.696535</td>\n",
       "      <td>11.674644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2          y\n",
       "0 -1.254599 -1.063645   0.295770\n",
       "1  4.507143 -0.265643  30.086577\n",
       "2  2.319939  3.545474  34.523622\n",
       "3  0.986585 -1.599956  -1.109427\n",
       "4 -3.439814  3.696497  49.341010\n",
       "5 -3.440055 -4.118656 -14.395442\n",
       "6 -4.419164  2.767984  43.154083\n",
       "7  3.661761  3.475476  43.267654\n",
       "8  1.011150 -3.181823  -9.254211\n",
       "9  2.080726 -0.696535  11.674644"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "N = 5000\n",
    "\n",
    "# Generate features from uniform distributions\n",
    "x1 = np.random.uniform(-5, 5, N)\n",
    "x2 = np.random.uniform(-5, 5, N)\n",
    "\n",
    "# Define the nonlinear relationship and add noise\n",
    "y = 1.5 * (x1 ** 2) + 0.5 * (x2 ** 3) + np.random.normal(loc=3, scale=3, size=N)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv('nonlinear_dataset.csv', index=False)\n",
    "\n",
    "df.head(10)  # Display the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y arrays\n",
    "X = df[['x1', 'x2']].values\n",
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4000, 2)\n",
      "Testing set shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model (original Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Performance:\n",
      "Training Set:\n",
      "MSE: 218.84992612063238\n",
      "R2: 0.6720857612554578\n",
      "\n",
      "Testing Set:\n",
      "MSE: 218.05222660659857\n",
      "R2: 0.6745129537467693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create a linear regression model\n",
    "baseline_model = LinearRegression()\n",
    "\n",
    "# Train the model on the original features\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_baseline = baseline_model.predict(X_train)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "# Evaluate the baseline model on the training set\n",
    "mse_train_baseline = mean_squared_error(y_train, y_train_pred_baseline)\n",
    "r2_train_baseline = r2_score(y_train, y_train_pred_baseline)\n",
    "\n",
    "print(\"\\nBaseline Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"MSE:\", mse_train_baseline)\n",
    "print(\"R2:\", r2_train_baseline)\n",
    "print(\"\\nTesting Set:\")\n",
    "print(\"MSE:\", mse_baseline)\n",
    "print(\"R2:\", r2_baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Features with PolynomialFeatures (`degree = 2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create PolynomialFeatures object with degree=2 (includes interaction terms)\n",
    "poly_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly_2 = poly_2.fit_transform(X_train)\n",
    "X_test_poly_2 = poly_2.transform(X_test)\n",
    "\n",
    "# Display the transformed feature names\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model with transformed Features (`degree = 2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "MSE: 95.31378244224537\n",
      "R2: 0.8571863972474734\n",
      "\n",
      "Testing Set:\n",
      "MSE: 90.00139440016171\n",
      "R2: 0.8656547173222298\n"
     ]
    }
   ],
   "source": [
    "# Create a linear regression model for the polynomial features\n",
    "poly_2_model = LinearRegression()\n",
    "\n",
    "# Train the model on the transformed features\n",
    "poly_2_model.fit(X_train_poly_2, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_poly_2 = poly_2_model.predict(X_test_poly_2)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_poly_2 = poly_2_model.predict(X_train_poly_2)\n",
    "\n",
    "# Evaluate the polynomial model\n",
    "mse_poly_2 = mean_squared_error(y_test, y_pred_poly_2)\n",
    "r2_poly_2 = r2_score(y_test, y_pred_poly_2)\n",
    "\n",
    "# Evaluate the polynomial model on the training set\n",
    "mse_train_poly_2 = mean_squared_error(y_train, y_train_pred_poly_2)\n",
    "r2_train_poly_2 = r2_score(y_train, y_train_pred_poly_2)\n",
    "\n",
    "print(\"\\nPolynomial Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"MSE:\", mse_train_poly_2)\n",
    "print(\"R2:\", r2_train_poly_2)\n",
    "print(\"\\nTesting Set:\")\n",
    "print(\"MSE:\", mse_poly_2)\n",
    "print(\"R2:\", r2_poly_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features with PolynomialFeatures (`degree = 3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2' 'x0^3' 'x0^2 x1' 'x0 x1^2' 'x1^3']\n"
     ]
    }
   ],
   "source": [
    "# Create PolynomialFeatures object with degree=2 (includes interaction terms)\n",
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly_3 = poly_3.fit_transform(X_train)\n",
    "X_test_poly_3 = poly_3.transform(X_test)\n",
    "\n",
    "# Display the transformed feature names\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_3.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model with transformed Features (`degree = 3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "MSE: 8.64661284180024\n",
      "R2: 0.9870443297925774\n",
      "\n",
      "Testing Set:\n",
      "MSE: 9.034015244301722\n",
      "R2: 0.9865149052434146\n"
     ]
    }
   ],
   "source": [
    "# Create a linear regression model for the polynomial features\n",
    "poly_3_model = LinearRegression()\n",
    "\n",
    "# Train the model on the transformed features\n",
    "poly_3_model.fit(X_train_poly_3, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_poly_3 = poly_3_model.predict(X_test_poly_3)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred_train_poly_3 = poly_3_model.predict(X_train_poly_3)\n",
    "\n",
    "# Evaluate the polynomial model\n",
    "mse_poly_3 = mean_squared_error(y_test, y_pred_poly_3)\n",
    "r2_poly_3 = r2_score(y_test, y_pred_poly_3)\n",
    "\n",
    "# Evaluate the polynomial model on the training set\n",
    "mse_poly_3_train = mean_squared_error(y_train, y_pred_train_poly_3)\n",
    "r2_poly_3_train = r2_score(y_train, y_pred_train_poly_3)\n",
    "\n",
    "print(\"\\nPolynomial Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"MSE:\", mse_poly_3_train)\n",
    "print(\"R2:\", r2_poly_3_train)\n",
    "print(\"\\nTesting Set:\")\n",
    "print(\"MSE:\", mse_poly_3)\n",
    "print(\"R2:\", r2_poly_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Testing MSE</th>\n",
       "      <th>Training R2</th>\n",
       "      <th>Testing R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>2</td>\n",
       "      <td>218.849926</td>\n",
       "      <td>218.052227</td>\n",
       "      <td>0.672086</td>\n",
       "      <td>0.674513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Degree 2</td>\n",
       "      <td>5</td>\n",
       "      <td>95.313782</td>\n",
       "      <td>90.001394</td>\n",
       "      <td>0.857186</td>\n",
       "      <td>0.865655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Degree 3</td>\n",
       "      <td>9</td>\n",
       "      <td>8.646613</td>\n",
       "      <td>9.034015</td>\n",
       "      <td>0.987044</td>\n",
       "      <td>0.986515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Features  Training MSE  Testing MSE  Training R2  \\\n",
       "0             Baseline         2    218.849926   218.052227     0.672086   \n",
       "1  Polynomial Degree 2         5     95.313782    90.001394     0.857186   \n",
       "2  Polynomial Degree 3         9      8.646613     9.034015     0.987044   \n",
       "\n",
       "   Testing R2  \n",
       "0    0.674513  \n",
       "1    0.865655  \n",
       "2    0.986515  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe to put these 3 models together, including model name, features, training mse, testing mse, training r2, testing r2\n",
    "models = ['Baseline', 'Polynomial Degree 2', 'Polynomial Degree 3']\n",
    "features = [X.shape[1], len(poly_2.get_feature_names_out()), len(poly_3.get_feature_names_out())]\n",
    "training_mse = [mse_train_baseline, mse_train_poly_2, mse_poly_3_train]\n",
    "testing_mse = [mse_baseline, mse_poly_2, mse_poly_3]\n",
    "training_r2 = [r2_train_baseline, r2_train_poly_2, r2_poly_3_train]\n",
    "testing_r2 = [r2_baseline, r2_poly_2, r2_poly_3]\n",
    "\n",
    "model_comparison = pd.DataFrame({   \n",
    "    'Model': models,\n",
    "    'Features': features,\n",
    "    'Training MSE': training_mse,\n",
    "    'Testing MSE': testing_mse,\n",
    "    'Training R2': training_r2,\n",
    "    'Testing R2': testing_r2\n",
    "})\n",
    "\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2' 'x0^3' 'x0^2 x1' 'x0 x1^2' 'x1^3']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# print out the feature names for the polynomial degree 3 model\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_3.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# print out the feature names for the polynomial degree 2 model\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `degreee = 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Model Performance:\n",
      "Training Set:\n",
      "MSE: 8.633776015235346\n",
      "R2: 0.98706356387817\n",
      "\n",
      "Testing Set:\n",
      "MSE: 8.991410070128255\n",
      "R2: 0.9865785020821749\n"
     ]
    }
   ],
   "source": [
    "# use polynominal degree of 4 to see if it improves the model\n",
    "poly_4 = PolynomialFeatures(degree=4, include_bias=False)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly_4 = poly_4.fit_transform(X_train)\n",
    "X_test_poly_4 = poly_4.transform(X_test)\n",
    "\n",
    "# Create a linear regression model for the polynomial features\n",
    "poly_4_model = LinearRegression()\n",
    "\n",
    "# Train the model on the transformed features\n",
    "poly_4_model.fit(X_train_poly_4, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_poly_4 = poly_4_model.predict(X_test_poly_4)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred_train_poly_4 = poly_4_model.predict(X_train_poly_4)\n",
    "\n",
    "# Evaluate the polynomial model\n",
    "mse_poly_4 = mean_squared_error(y_test, y_pred_poly_4)\n",
    "r2_poly_4 = r2_score(y_test, y_pred_poly_4)\n",
    "\n",
    "# Evaluate the polynomial model on the training set\n",
    "mse_poly_4_train = mean_squared_error(y_train, y_pred_train_poly_4)\n",
    "r2_poly_4_train = r2_score(y_train, y_pred_train_poly_4)\n",
    "\n",
    "print(\"\\nPolynomial Model Performance:\")\n",
    "print(\"Training Set:\")\n",
    "print(\"MSE:\", mse_poly_4_train)\n",
    "print(\"R2:\", r2_poly_4_train)\n",
    "print(\"\\nTesting Set:\")\n",
    "print(\"MSE:\", mse_poly_4)\n",
    "print(\"R2:\", r2_poly_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Features: 14\n",
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0^2' 'x0 x1' 'x1^2' 'x0^3' 'x0^2 x1' 'x0 x1^2' 'x1^3' 'x0^4'\n",
      " 'x0^3 x1' 'x0^2 x1^2' 'x0 x1^3' 'x1^4']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names for the polynomial degree 4 model\n",
    "print(\"\\nNumber of Features:\", len(poly_4.get_feature_names_out()))\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_4.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key takeaway:\n",
    "\n",
    "In `scikit-learn`, the built-in `PolynomialFeatures` transformer is somewhat “all or nothing”: by default, it generates **all** polynomial terms (including interactions) up to a certain degree. You can toggle:\n",
    "\n",
    "* `interaction_only=True` to generate only cross-terms\n",
    "* `include_bias=False` to exclude the constant (bias) term,\n",
    "* `degree` to control how high the polynomial powers go.\n",
    "\n",
    "However, if you want **fine-grained control** over exactly which terms get generated (for example, only certain interaction terms, or only a subset of polynomial terms), you will need to create those features manually or write a custom transformer (skipped for beginner level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `interaction_only` for Cross Terms Only\n",
    "\n",
    "If your goal is only to capture interaction terms (i.e., $ x_1 \\times x_2 $, but no squares, cubes, etc.), you can set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x0' 'x1' 'x0 x1']\n"
     ]
    }
   ],
   "source": [
    "poly_int = PolynomialFeatures(degree=6, \n",
    "                             interaction_only=True, \n",
    "                             include_bias=False)\n",
    "\n",
    "X_transformed = poly_int.fit_transform(X)\n",
    "\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(poly_int.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be very selective—say, just add $x_1^2$ and $ x_1 \\times x_2 $ but not  $x_2^2$ —the simplest approach is to create columns by hand. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Feature Names:\n",
      "['x1', 'x2', 'x1^2', 'x1*x2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -1.25459881,  -1.0636448 ,   1.57401818,   1.3344475 ],\n",
       "       [  4.50714306,  -0.26564341,  20.3143386 ,  -1.19729284],\n",
       "       [  2.31993942,   3.54547393,   5.3821189 ,   8.22528473],\n",
       "       [  0.98658484,  -1.59995614,   0.97334965,  -1.57849247],\n",
       "       [ -3.4398136 ,   3.69649685,  11.83231757, -12.71526011]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X1 = X[:, 0].reshape(-1, 1)  # feature 1\n",
    "X2 = X[:, 1].reshape(-1, 1)  # feature 2\n",
    "\n",
    "# Manually create specific transformations\n",
    "X1_sq = X1**2\n",
    "X1X2 = X1 * X2\n",
    "\n",
    "# Combine them as you like\n",
    "X_new = np.hstack([X1, X2, X1_sq, X1X2])\n",
    "\n",
    "print(\"\\nTransformed Feature Names:\")\n",
    "print(['x1', 'x2', 'x1^2', 'x1*x2'])\n",
    "\n",
    "X_new[:5]  # Display the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `PolynomialFeatures` (or any other scikit-learn transformer), the fitting step is always done on the training data—not on the test data. This is a fundamental principle of machine learning pipelines: we do not use the test set for any part of model training (including feature encoding, feature generation, scaling, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
